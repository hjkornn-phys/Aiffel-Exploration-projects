{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "concerned-mambo",
   "metadata": {},
   "source": [
    "# Machine Reading Comprehension\n",
    "주어진 글을 읽고 질문이 주어지면 답을 내는 구조이다. 이 때, 답은 지문에 직접적으로 들어 있지 않아도 되며, BERT등 트랜스포머 응용 구조로 SQuAD 데이터셋 기준 SOTA의 정확도는  이미 사람의 평균 정확도를 넘어섰다.\n",
    "사용된 학습 방식은 방대한 언어 모델로 학습한 뒤 fine-tuning하는 것으로, 어떠한 task에도 적용 가능하다는 것을 보여 transfer learning이 더욱 널리 사용되는 계기가 되었다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-knock",
   "metadata": {},
   "source": [
    "## 0. import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polyphonic-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-stocks",
   "metadata": {},
   "source": [
    "## 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "banned-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json_tree(data, indent=\"\"):\n",
    "    for key, value in data.items():\n",
    "        if type(value) == list:     # list 형태의 item은 첫번째 item만 출력\n",
    "            print(f'{indent}- {key}: [{len(value)}]')\n",
    "            print_json_tree(value[0], indent + \"  \")\n",
    "        else:\n",
    "            print(f'{indent}- {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structural-heading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- version: KorQuAD_v1.0_train\n",
      "- data: [1420]\n",
      "  - paragraphs: [3]\n",
      "    - qas: [8]\n",
      "      - answers: [1]\n",
      "        - text: 교향곡\n",
      "        - answer_start: 54\n",
      "      - id: 6566495-0-0\n",
      "      - question: 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "    - context: 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "  - title: 파우스트_서곡\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_qna/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_qna/models'\n",
    "\n",
    "# 훈련데이터 확인\n",
    "\n",
    "# 1420개 중 1번째 data\n",
    "# 3개 중 1번째 paragraph\n",
    "# 8개 중 1번째 qna\n",
    "# 1개 중 1번째 answer\n",
    "\n",
    "train_json_path = data_dir + '/KorQuAD_v1.0_train.json'\n",
    "with open(train_json_path) as f:\n",
    "    train_json = json.load(f)\n",
    "    print_json_tree(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "refined-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- version: KorQuAD_v1.0_dev\n",
      "- data: [140]\n",
      "  - paragraphs: [2]\n",
      "    - qas: [7]\n",
      "      - answers: [1]\n",
      "        - text: 1989년 2월 15일\n",
      "        - answer_start: 0\n",
      "      - id: 6548850-0-0\n",
      "      - question: 임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
      "    - context: 1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "  - title: 임종석\n"
     ]
    }
   ],
   "source": [
    "# 검증데이터 확인\n",
    "dev_json_path = data_dir + '/KorQuAD_v1.0_dev.json'\n",
    "with open(dev_json_path) as f:\n",
    "    dev_json = json.load(f)\n",
    "    print_json_tree(dev_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mighty-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paragraphs\": [\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"교향곡\",\n",
      "              \"answer_start\": 54\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-0\",\n",
      "          \"question\": \"바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1악장\",\n",
      "              \"answer_start\": 421\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-1\",\n",
      "          \"question\": \"바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"베토벤의 교향곡 9번\",\n",
      "              \"answer_start\": 194\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-2\",\n",
      "          \"question\": \"바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"파우스트\",\n",
      "              \"answer_start\": 15\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-0-0\",\n",
      "          \"question\": \"1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"합창교향곡\",\n",
      "              \"answer_start\": 354\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-0-1\",\n",
      "          \"question\": \"파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1839\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-0\",\n",
      "          \"question\": \"바그너가 파우스트를 처음으로 읽은 년도는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"파리\",\n",
      "              \"answer_start\": 410\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-1\",\n",
      "          \"question\": \"바그너가 처음 교향곡 작곡을 한 장소는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"드레스덴\",\n",
      "              \"answer_start\": 534\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-2\",\n",
      "          \"question\": \"바그너의 1악장의 초연은 어디서 연주되었는가?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-0\",\n",
      "          \"question\": \"바그너의 작품을 시인의 피로 쓰여졌다고 극찬한 것은 누구인가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-1\",\n",
      "          \"question\": \"잊혀져 있는 파우스트 서곡 1악장을 부활시킨 것은 누구인가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20루이의 금\",\n",
      "              \"answer_start\": 345\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-2\",\n",
      "          \"question\": \"바그너는 다시 개정된 총보를 얼마를 받고 팔았는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-1-0\",\n",
      "          \"question\": \"파우스트 교향곡을 부활시킨 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-1-1\",\n",
      "          \"question\": \"파우스트 교향곡을 피아노 독주용으로 편곡한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-0\",\n",
      "          \"question\": \"1악장을 부활시켜 연주한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-1\",\n",
      "          \"question\": \"파우스트 교향곡에 감탄하여 피아노곡으로 편곡한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1840년\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-2\",\n",
      "          \"question\": \"리스트가 바그너와 알게 된 연도는?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"한편 1840년부터 바그너와 알고 지내던 리스트가 잊혀져 있던 1악장을 부활시켜 1852년에 바이마르에서 연주했다. 이것을 계기로 바그너도 이 작품에 다시 관심을 갖게 되었고, 그 해 9월에는 총보의 반환을 요구하여 이를 서곡으로 간추린 다음 수정을 했고 브라이트코프흐 & 헤르텔 출판사에서 출판할 개정판도 준비했다. 1853년 5월에는 리스트가 이 작품이 수정되었다는 것을 인정했지만, 끝내 바그너의 출판 계획은 무산되고 말았다. 이후 1855년에 리스트가 자신의 작품 파우스트 교향곡을 거의 완성하여 그 사실을 바그너에게 알렸고, 바그너는 다시 개정된 총보를 리스트에게 보내고 브라이트코프흐 & 헤르텔 출판사에는 20루이의 금을 받고 팔았다. 또한 그의 작품을 “하나하나의 음표가 시인의 피로 쓰여졌다”며 극찬했던 한스 폰 뷜로가 그것을 피아노 독주용으로 편곡했는데, 리스트는 그것을 약간 변형되었을 뿐이라고 지적했다. 이 서곡의 총보 첫머리에는 파우스트 1부의 내용 중 한 구절을 인용하고 있다.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"주제, 동기\",\n",
      "              \"answer_start\": 70\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-0\",\n",
      "          \"question\": \"서주에는 무엇이 암시되어 있는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"제1바이올린\",\n",
      "              \"answer_start\": 148\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-1\",\n",
      "          \"question\": \"첫부분에는 어떤 악기를 사용해 더욱 명확하게 나타내는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"소나타 형식\",\n",
      "              \"answer_start\": 272\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-2\",\n",
      "          \"question\": \"주요부는 어떤 형식으로 되어 있는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"저음 주제\",\n",
      "              \"answer_start\": 102\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-2-0\",\n",
      "          \"question\": \"첫 부분의 주요주제를 암시하는 주제는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D장조\",\n",
      "              \"answer_start\": 409\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-2-1\",\n",
      "          \"question\": \"제2주제의 축소된 재현부의 조성은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"4/4박자\",\n",
      "              \"answer_start\": 35\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-0\",\n",
      "          \"question\": \"곡이 시작할때의 박자는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"고뇌와 갈망 동기, 청춘의 사랑 동기\",\n",
      "              \"answer_start\": 115\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-1\",\n",
      "          \"question\": \"이 곡의 주요 주제는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D장조\",\n",
      "              \"answer_start\": 409\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-2\",\n",
      "          \"question\": \"제 2주제에선 무슨 장조로 재현되는가?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"이 작품은 라단조, Sehr gehalten(아주 신중하게), 4/4박자의 부드러운 서주로 서주로 시작되는데, 여기에는 주요 주제, 동기의 대부분이 암시, 예고되어 있다. 첫 부분의 저음 주제는 주요 주제(고뇌와 갈망 동기, 청춘의 사랑 동기)를 암시하고 있으며, 제1바이올린으로 더욱 명확하게 나타난다. 또한 그것을 이어받는 동기도 중요한 역할을 한다. 여기에 새로운 소재가 더해진 뒤에 새로운 주제도 연주된다. 주요부는 Sehr bewegt(아주 격동적으로), 2/2박자의 자유로운 소나타 형식으로 매우 드라마틱한 구상과 유기적인 구성을 하고 있다. 여기에는 지금까지의 주제나 소재 외에도 오보에에 의한 선율과 제2주제를 떠올리게 하는 부차적인 주제가 더해지는데, 중간부에서는 약보3이 중심이 되고 제2주제는 축소된 재현부에서 D장조로 재현된다. 마지막에는 주요 주제를 회상하면서 조용히 마친다.\"\n",
      "    }\n",
      "  ],\n",
      "  \"title\": \"파우스트_서곡\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# json의 실제 형태\n",
    "print(json.dumps(train_json[\"data\"][0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-marriage",
   "metadata": {},
   "source": [
    "## 2. preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-conservative",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-british",
   "metadata": {},
   "source": [
    "공백이 있는지 확인하는 함수. 각각 빈칸, 탭, 반환, 개행, 유니코드 스페이스를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chicken-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_whitespace(c):\n",
    "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-protein",
   "metadata": {},
   "source": [
    "어절 정보는 중요한 정보이므로 공백을 처리하여 각 글자가 몇번째 어절인지 기록한다. (토큰화만 진행하면 이 정보는 유실된다)\n",
    "\n",
    "만일 슬라이싱만으로 해결하려면 공백이 여러 개인 경우 문제가 생긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-steel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('파우스트', '파우스트')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whitespace가 2개인 경우를 처리해야 함\n",
    "\n",
    "string1 = '1839년 파우스트를 읽었다.'\n",
    "string2 = '1839년  파우스트를 읽었다.'\n",
    "string1[6:10], string2[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-background",
   "metadata": {},
   "source": [
    "따라서 `_is_whitespace()`를 사용해 어절 단위로 구분한 결과를 반환하게 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fancy-blade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : ['1'] : [0]\n",
      "'8' : ['18'] : [0, 0]\n",
      "'3' : ['183'] : [0, 0, 0]\n",
      "'9' : ['1839'] : [0, 0, 0, 0]\n",
      "'년' : ['1839년'] : [0, 0, 0, 0, 0]\n",
      "' ' : ['1839년'] : [0, 0, 0, 0, 0, 0]\n",
      "'파' : ['1839년', '파'] : [0, 0, 0, 0, 0, 0, 1]\n",
      "'우' : ['1839년', '파우'] : [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "'스' : ['1839년', '파우스'] : [0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "'트' : ['1839년', '파우스트'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "'를' : ['1839년', '파우스트를'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "' ' : ['1839년', '파우스트를'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "'읽' : ['1839년', '파우스트를', '읽'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2]\n",
      "'었' : ['1839년', '파우스트를', '읽었'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2]\n",
      "'다' : ['1839년', '파우스트를', '읽었다'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "'.' : ['1839년', '파우스트를', '읽었다.'] : [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = []\n",
    "char_to_word = []\n",
    "prev_is_whitespace = True\n",
    "\n",
    "# 첫번째 문장(string1)에 대해 띄어쓰기 영역 정보를 표시\n",
    "for c in string1:\n",
    "    if _is_whitespace(c):\n",
    "        prev_is_whitespace = True\n",
    "    else:\n",
    "        if prev_is_whitespace:\n",
    "            word_tokens.append(c)\n",
    "        else:\n",
    "            word_tokens[-1] += c\n",
    "        prev_is_whitespace = False    \n",
    "    char_to_word.append(len(word_tokens) - 1)\n",
    "    print(f'\\'{c}\\' : {word_tokens} : {char_to_word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "graphic-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : ['1'] : [0]\n",
      "'8' : ['18'] : [0, 0]\n",
      "'3' : ['183'] : [0, 0, 0]\n",
      "'9' : ['1839'] : [0, 0, 0, 0]\n",
      "'년' : ['1839년'] : [0, 0, 0, 0, 0]\n",
      "' ' : ['1839년'] : [0, 0, 0, 0, 0, 0]\n",
      "' ' : ['1839년'] : [0, 0, 0, 0, 0, 0, 0]\n",
      "'파' : ['1839년', '파'] : [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "'우' : ['1839년', '파우'] : [0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "'스' : ['1839년', '파우스'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "'트' : ['1839년', '파우스트'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "'를' : ['1839년', '파우스트를'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "' ' : ['1839년', '파우스트를'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "'읽' : ['1839년', '파우스트를', '읽'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2]\n",
      "'었' : ['1839년', '파우스트를', '읽었'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2]\n",
      "'다' : ['1839년', '파우스트를', '읽었다'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
      "'.' : ['1839년', '파우스트를', '읽었다.'] : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = []\n",
    "char_to_word = []\n",
    "prev_is_whitespace = True\n",
    "\n",
    "# 두번째 문장(string2)에 대해 띄어쓰기 영역 정보를 표시\n",
    "for c in string2:\n",
    "    if _is_whitespace(c):\n",
    "        prev_is_whitespace = True\n",
    "    else:\n",
    "        if prev_is_whitespace:\n",
    "            word_tokens.append(c)\n",
    "        else:\n",
    "            word_tokens[-1] += c\n",
    "        prev_is_whitespace = False    \n",
    "    char_to_word.append(len(word_tokens) - 1)\n",
    "    print(f'\\'{c}\\' : {word_tokens} : {char_to_word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "scheduled-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_whitespace(string):\n",
    "    word_tokens = []\n",
    "    char_to_word = []\n",
    "    prev_is_whitespace = True\n",
    "\n",
    "    for c in string:\n",
    "        if _is_whitespace(c):\n",
    "            prev_is_whitespace = True\n",
    "        else:\n",
    "            if prev_is_whitespace:\n",
    "                word_tokens.append(c)\n",
    "            else:\n",
    "                word_tokens[-1] += c\n",
    "            prev_is_whitespace = False    \n",
    "        char_to_word.append(len(word_tokens) - 1)\n",
    "    \n",
    "    return word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1839년', '파우스트를', '읽었다.'], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tokenize_whitespace(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arranged-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : 0\n",
      "'8' : 0\n",
      "'3' : 0\n",
      "'9' : 0\n",
      "'년' : 0\n",
      "' ' : 0\n",
      "'파' : 1\n",
      "'우' : 1\n",
      "'스' : 1\n",
      "'트' : 1\n",
      "'를' : 1\n",
      "' ' : 1\n",
      "'읽' : 2\n",
      "'었' : 2\n",
      "'다' : 2\n",
      "'.' : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['1839년', '파우스트를', '읽었다.'], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens, char_to_word = _tokenize_whitespace(string1)\n",
    "for c, i in zip(list(string1), char_to_word):\n",
    "    print(f'\\'{c}\\' : {i}')\n",
    "\n",
    "word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "increased-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' : 0\n",
      "'8' : 0\n",
      "'3' : 0\n",
      "'9' : 0\n",
      "'년' : 0\n",
      "' ' : 0\n",
      "' ' : 0\n",
      "'파' : 1\n",
      "'우' : 1\n",
      "'스' : 1\n",
      "'트' : 1\n",
      "'를' : 1\n",
      "' ' : 1\n",
      "'읽' : 2\n",
      "'었' : 2\n",
      "'다' : 2\n",
      "'.' : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['1839년', '파우스트를', '읽었다.'],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens, char_to_word = _tokenize_whitespace(string2)\n",
    "for c, i in zip(list(string2), char_to_word):\n",
    "    print(f'\\'{c}\\' : {i}')\n",
    "\n",
    "word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-sharing",
   "metadata": {},
   "source": [
    "### create vocabulary - subword segmentation\n",
    "sentencepiece의 동작은 precompiled list에서 어떤 token을 선택할지 정하는 알고리즘이다.\n",
    "\n",
    "**Strengths of SentencePiece**\n",
    "* It’s implemented in C++ and blazingly fast. You can train a tokenizer on a corpus of 10⁵ characters in seconds.\n",
    "* It’s also blazingly fast to tokenize. This means you can use it directly on raw text data, without the need to store your tokenized data to disk.\n",
    "* Subword regularization is like a text version of data augmentation, and can greatly improve the quality of your model.\n",
    "* It’s whitespace agnostic. You can train non-whitespace delineated languages like Chinese and Japanese with the same ease as you would English or French.\n",
    "* It can work at the byte level, so you **almost** never need to use [UNK] or [OOV] tokens. This is not specific only to SentencePiece.\n",
    "\n",
    "\n",
    "\n",
    "[참고자료](https://towardsdatascience.com/sentencepiece-tokenizer-demystified-d0a3aac19b15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "angry-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁1839', '년', '▁', '파우스트', '를', '▁읽', '었다', '.'], [0, 2, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")\n",
    "\n",
    "# word를 subword로 변경하면서 index 저장\n",
    "word_to_token = []\n",
    "context_tokens = []\n",
    "for (i, word) in enumerate(word_tokens):\n",
    "    word_to_token.append(len(context_tokens))\n",
    "    tokens = vocab.encode_as_pieces(word)  # SentencePiece를 사용해 Subword로 쪼갭니다.\n",
    "    for token in tokens:\n",
    "        context_tokens.append(token)\n",
    "\n",
    "context_tokens, word_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "agreed-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize_vocab(vocab, context_words):\n",
    "    word_to_token = []\n",
    "    context_tokens = []\n",
    "    for (i, word) in enumerate(context_words):\n",
    "        word_to_token.append(len(context_tokens))\n",
    "        tokens = vocab.encode_as_pieces(word)\n",
    "        for token in tokens:\n",
    "            context_tokens.append(token)\n",
    "    return context_tokens, word_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "equal-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1839년', '파우스트를', '읽었다.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['▁1839', '년', '▁', '파우스트', '를', '▁읽', '었다', '.'], [0, 2, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_tokens)  # 처리해야 할 word 단위 입력\n",
    "\n",
    "context_tokens, word_to_token = _tokenize_vocab(vocab, word_tokens)\n",
    "context_tokens, word_to_token   # Subword 단위로 토큰화한 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-particular",
   "metadata": {},
   "source": [
    "### Improve Span\n",
    "MRC에서는 정확한 정답의 영역을 찾는 것이 매우 중요하다. 주어진 정답은 `answer_start`로 인덱스만 주어지지만, sentencepiece tokenizing을 했으므로, 정답에 대해서도 전처리된 문장에서의 위치를 찾는것이 중요하다. 주어진 정보를 최대한 활용하여 서치를 개선한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "strategic-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[context]  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "[question]  바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "[answer]  교향곡\n",
      "[answer_start] index:  54 character:  교\n",
      "[answer_end]index:  56 character:  곡\n"
     ]
    }
   ],
   "source": [
    "context = train_json['data'][0]['paragraphs'][0]['context']\n",
    "question = train_json['data'][0]['paragraphs'][0]['qas'][0]['question']\n",
    "answer_text = train_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['text']\n",
    "answer_start = train_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start']\n",
    "answer_end = answer_start + len(answer_text) - 1\n",
    "\n",
    "print('[context] ', context)\n",
    "print('[question] ', question)\n",
    "print('[answer] ', answer_text)\n",
    "print('[answer_start] index: ', answer_start, 'character: ', context[answer_start])\n",
    "print('[answer_end]index: ', answer_end, 'character: ', context[answer_end])\n",
    "\n",
    "# answer_text에 해당하는 context 영역을 정확히 찾아내야 합니다. \n",
    "assert context[answer_start:answer_end + 1] == answer_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-slovakia",
   "metadata": {},
   "source": [
    "정답 영역을 추적하기 위해 tokenize의 과정을 따라간다. 어절 단위로 분리 하여 어느 어절에 속하는지 특정하고, 해당 어절에 속하는 subword 중 해당하는 영역을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "shared-rotation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1839년', '바그너는', '괴테의', '파우스트을', '처음', '읽고', '그', '내용에', '마음이', '끌려', '이를', '소재로', '해서', '하나의', '교향곡을', '쓰려는', '뜻을', '갖는다.', '이', '시기']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3],\n",
       " '1839년 바그너는 괴테의 파우스트을')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context를 띄어쓰기(word) 단위로 토큰화한 결과를 살펴봅니다. \n",
    "word_tokens, char_to_word = _tokenize_whitespace(context)\n",
    "\n",
    "print( word_tokens[:20])\n",
    "\n",
    "char_to_word[:20], context[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extraordinary-experiment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['▁1839', '년']\n",
      "2 ['▁바그너', '는']\n",
      "4 ['▁괴테', '의']\n",
      "6 ['▁', '파우스트', '을']\n",
      "9 ['▁처음']\n",
      "10 ['▁읽고']\n",
      "11 ['▁그']\n",
      "12 ['▁내용에']\n",
      "13 ['▁마음이']\n",
      "14 ['▁끌려']\n",
      "15 ['▁이를']\n",
      "16 ['▁소재로']\n",
      "17 ['▁해서']\n",
      "18 ['▁하나의']\n",
      "19 ['▁교향곡', '을']\n",
      "21 ['▁쓰', '려는']\n",
      "23 ['▁뜻을']\n",
      "24 ['▁갖는다', '.']\n",
      "26 ['▁이']\n",
      "27 ['▁시기']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기(word) 단위로 쪼개진 context(word_tokens)를 Subword로 토큰화한 결과를 살펴봅니다. \n",
    "context_tokens, word_to_token = _tokenize_vocab(vocab, word_tokens)\n",
    "for i in range(min(20, len(word_to_token) - 1)):\n",
    "    print(word_to_token[i], context_tokens[word_to_token[i]:word_to_token[i + 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-hunter",
   "metadata": {},
   "source": [
    "어절 찾기 - '교향곡을' 이 추출되었다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "common-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, '교향곡', ['교향곡을'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer_start와 answer_end로부터 word_start와 word_end를 구합니다. \n",
    "word_start = char_to_word[answer_start]\n",
    "word_end = char_to_word[answer_end]\n",
    "word_start, word_end, answer_text, word_tokens[word_start:word_end + 1]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAACdCAYAAADWil6vAAAgAElEQVR4Ae19y7HkSrJcK0EFKAE14IJSzY6acE8VKMQ142yoxLW7nA2NTYue52+8/XlkJrIAFE4dP2awyPTwiAx4BQ6iuu/nx8/8RIEoEAWiQBSIAlEgCnyMAj8+5k5yI1EgCkSBKBAFokAUiAI/M9ylCaJAFIgCUSAKRIEo8EEKZLj7oA8ztxIFokAUiAJRIApEgQx36YEoEAWiQBSIAlEgCnyQAhnuPujDzK1EgSgQBaJAFIgCUSDD3YU98Oeff/78+9///vOPP/7IFQ3SA+mB9EB6ID2QHrilBzLcXTjc1WD3119//fzHP/6RKxqkB9ID6YH0QHogPXBLD2S4u3C4qz+xy2CXwTY9kB5ID6QH0gPpgTt7IMNdhrsMoPkmmR5ID6QH0gPpgQ/qgQx3Ge7yQH/QA33nN8OclT+JSA+kB9IDz+yBDHcZ7jLcZbhLD6QH0gPpgfTAB/VAhrsMd3mgP+iBzrfoZ36LzueSzyU9kB64swcy3GW4y3CX4S49kB5ID6QH0gMf1AMfM9z9l//6P37ienVeQ56yr/x8xX9b9sePH3nAT3jAo2O+pd/5LT1npd/SA+kB7oG3DHevDk1u4Brl7HyF86V5uzjldfsrh7sf//38IeydA8mVZ1+Zmx8mXb/rXK3j6P7H3/62NeAfjWM+r1fr3Ymp3BXHF5+3m5NzPHm9e3+vxEFr1eWVnJor+ww26YHfe+DjhzsMbzqAucFNMd1rjtn+acPdbCB85zCyevYqjx/0nRiO311feS6/GHm9UitetmwR1+ViLq9nceWf8bszu1jgOPssO6rjrDOO5jlSE+vMa5w5y8UxzOU1cq1YjeM9rzlX4Xqpn/dZ//5Cjx7RAz3w8cNdDWBuSFvBHAcD3cgHzpXDHT7AI3Y03F05iKzUuHr+Ko/P3Inh+FfWV53NL0dev1JrxR7JxVxeo4bCRhfzsGbLOXldHN1znFuP6kAuWBf/LuxITTNu5y/c+YDBHtHAxTDG61Fe8MriGvHjy3CTHvhnDzxmuKthiS8MSKt2NGw53wrmOKhn5ANnNNxh0CqLNTclsJlfY8BHPPyMq6843RACXC3yIhZ+xWd+xMFyvK6Lw5f6u7NcbsY45wqOc7s4+FEP789Y44X3K//Bv0LFC1It6uLcwDrLXF53fMaZz2twFJvtETezlQeXcoHrWcq7c3+klhm38zu8MOCwR+5bYzhf5VE/coMHCxy2i4M/NsNdeuCBwx2GorIrw9Mq3+VawRyHz5ytZ8MdD1m8rubEMNY1qvIRw3zl6P43bvMvUmDYUYtY4L/OlxwYfsBlq3G8Z56uRzz2devKN/Kxn3mM67r2RzDwdyxeemqP5nIvSYf9ui8aiPhcnNnFaazju9gZ5mpA7s4ihv18Dq+Z49bM7dYVVz5cnAcxsOpDjPMzl9cz7ign+7BG7lle8NRqHO95zXEjvHydn3NkneEuPfDNhzsMkDXA4dJh7erhTpuQhy9eK6/2zq/YbM95dZCBD7jaXzXIMKcYYpAL1uEOA59tx3M4MNjKw2u3Z2zEVR/XyOtVHseM1vySe+Vlh1jkg3Vng+t8hXV+xlfWyM9chzk/eJ11MYzxussBHNyyvGY/8MJ4jb1iwLscwDvb5QMO28V3+CtxFYuL83c5FddY9XPOrDPUpQd+74FH/bUsD1dHB6sR3/lWMMfhGmfr2Z/caTPyMMZr5dXe+RWb7TlvN4QAV/urhi823OEe9L4L18vdn8YjhvPpWmPUf3TPLzheH8mjL03Edvk6/Egc58D5sMgDy1yHOT94I4vzYEfckQ/ncx5gFcfrlT3O4jjODf/Igs+W+ZwbOHNHa/CvtlrD1ecl/+/DQPT4LD0y3NGEpsOc7om69NfGGe78f67FDTwOc79sOp7DgZXFpTnBUbz26tM9YrrcLgdijlp98fF+NxfHVT7eY93hM7/GYQ9b8bwe5WNerXEhZsUiprMrOcBBjtrzGnvwYIvj1sDKMsftmXt0rbldvOM4zMUqNoob+TRP9p81bOTzvPfzzHBHE5sOc7on6rcZ7uqBxFADi4dU98zVNWI63OXiGKw7nsOBwbqz2YczYNWne/Bgnd9h4B+1/GLk9ZE8iINFrO5n+Myv+bCHrXhed/mKwzxeI+ZVezQn18TrlXvqzlJc97N7HPFHPuR1HIeBP7IVN7pc7IgPn4sLdu/AEL2/jt4Z7mhi02FO90RdWs7+5I7/2pTX9QDpXh8q51dstv8POc1fs/6q5d9wN6gwxmuO03PUV3Ea62I0Tjmco1trDuYhHzBYxTWH83cccHdsveQQx2tgM8sxvK443SOXwwsDDgs+LOMraxdXGMe6PeJmtvJ01yxW/VwTr4t3dI/cHFdr3oMzskf5nKuL7XCOdetR3MjncgHbjUN87NcZSvJZnfNZfdvhrqazGt740ont6uGumrgGMB3CgI+afCWm4zj815kbwx3idBACPrwHGupcfBdb3I7vfI7LGGJgcS5z3P2AD4s4WI0HvmP55cbrlVzF1xjG1Iec4KhlP9ZqOQY+PofX8MO62PKNYhDr7G5cl4vz8Ro1FoaLcyhXfYgZ8TgGa45za/A6685zWBfPuDufMeaurndrWc0f3jnDRHR8lo5vGe50iDpjPxrSjuY/K9fsT+6e+DCcOZDs3B8GJbU7ud4Z824dj9z77svzaBzzeb1a605M5a640bV6/nfi7Wp9hUZPquWK+0vOZw1Fn/J5fMxwd3SAu4M/Gu4+pYFyH/nFlB5ID6QH0gPpgWf1QIa7C6e8DHfPavb88snnkR5ID6QH0gPfoQcy3GW4+/d/SP87NHzuMb/Y0wPpgfRAeuDTeyDDXYa7DHf/9r8P+/SHPfeXF1p6ID2QHvgePZDhLsNdhrsMd+mB9EB6ID2QHvigHshwl+EuD/QHPdD5Vv49vpXnc87nnB5ID4x6IMNdhrsMdxnu0gPpgfRAeiA98EE9kOEuw10e6A96oEff5OLLN/30QHogPfA9eiDDXYa7DHcZ7tID6YH0QHogPfBBPZDhLsNdHugPeqDzrfx7fCvP55zPOT2QHhj1QIa7DHcZ7jLcpQfSA+mB9EB64IN6IMNdhrs80B/0QI++ycWXb/rpgfRAeuB79ECGuwx3Ge4y3KUH0gPpgfRAeuCDeiDDXYa7PNAf9EDnW/n3+Faezzmfc3ogPTDqgQx3Ge4y3GW4Sw+kB9ID6YH0wAf1QIa7DHd5oD/ogR59k4sv3/TTA+mB9MD36IEMdxnuMtxluEsPpAfSA+mB9MAH9UCGuwx3eaA/6IHOt/Lv8a08n3M+5/RAemDUAxnuMtxluMtwlx5ID6QH0gPpgQ/qgQx3Ge7yQH/QAz36JhdfvumnB9ID6YHv0QMZ7jLcZbjLcJceSA+kB9ID6YEP6oEMdxnu8kB/0AOdb+Xf41v5d/ycf/z4kd9V+V31qwfSC/PfcxnuMtw96hdmHtrfH9qvpsdXq/fsIenK+78y99k6HMm3cl8rnCNn7nCfUMNO3RVzZe1X5h7d77vOHdX0JF+Guw8b7q5o+N2cO3E7MU96oM6uZVWPVd6R+nZy7sQcqelO7s697MSs3tOVuVdruIK3cl8rnCtq45xPqIHrObJerX2Vx2fvxHD87vpd5+7We3dchrsMd9M/udt9iHbidmLufmjuPG9Vj1Xekdp3cu7EHKnpTu7OvezE3HlPTzxrptnMf9c9PaWOnftdrX2VxzXsxHD8K+t3nv1K3XfEZrh783BXzYlLP3CHA4PlGGCw7Ks1cFj4a481LDBwYeGfWfBhHd/5ClMuY4iBBRd7WOCwwGGB79rKU7FqOV93Fsdg3cU5P3NRA87q+PBrbLcHH9bxnK8w5TKGGFhwsYcF/i6LOmBdHc5XmHIZQwwsuNjDAmdbPt7XGny14HU4/M7qObrnc7t4nMt+YJoPe/g5Bmcp5nDkYW6XE/HOD0zzYQ8/n7O75pyoSXN153Es1hzLcc7PXJyNmI4PP8c6LmOIgUUs9rDAYYHDAmdbPt5n/a9/rCfD3RuHO21M3q+sq5GZ5/ZoduUpl/28Vh7yrVjNwzHs69Z6NvOQCxis4prD+YEdsThPLXIArz2vsVesi+t44MOOeOzjNWI7O+Kyr1tX3pGP/cxjvKvtn/j//fm//vPPn//TXv/v5/9+8R8+15q4FvZ1a70P5iEXMFjFsddcjOsauWDZ7zD211o5o/3Ix7lGvPKxn9ec4+l1an0re9yrWsQCrz2vsVesi+t44MOOeOzr1qhrlA+xsI6rPs3rYoDF/nPAy3D3puHONS+a0vmAwXZc9Xe8wpnbrZWHfCuWczLf4cBg3bnsQz5gsIq7POC8YnGe2u488Dp/h3PcqN6O53CHudwdz+HAYN39sA/nAYNVHPt3WK0JNTgcGGxxee32jB3hog5nOQ+vwXUYfLDK4T2vle984KhlLq/BY4zX8JdVnPe8RgwwWOAjy1xeI8Zh8K1YxKutWGCchzFedxzgHRd+2I7ncGCwlYPXbs/YiKs+1Kd2ladx32Gf4e4bDXf1IOjFTQ4fY7XefYC6OIcDU8u1lM9drkbkQTzisH/VIr9aV4tiiNEaHO4wjdP87HfxDuMYrDuew4GpRa6y5XMXfMrlvV+/50/ucI9cEzC1ynnl/pGbc/Ja/e4s5XA81srhPa+V73zglC0/X/C5OMZ4jRjk6/YuBhgsx/K6/HzB5+IcBv6KRbzaigXGeRjjdccB3nHhh+14DgemFrnKls9d8ClX98jNOK9nfuZ+t3WGu2803M2aGw+h8nYfoC7O4cDK4jpSB+IRo3vGOx84KxY51FYsMM7DGK87DvCOCz9sx3O4w5CHbcdzOLCyuDhXrcFR3PlGXBd/BdbV4HBgZXFpTeAoXnv16d5xOM9RPse6NfLBgqP7woHBgstWfbznNWIY4zX8sPDBKo59WXBg2Ye1+njP644PfNUip9qKB8a5GON1xwHeceGH7XgOB1YWF/LAgoM9W/XpHtwud/m7GMR+Z5vhLsPdr38glR8SXr/yAGkePGgOBwbrzmUfcsGqT/fgwc784I0scsCCq/vCGeM1YpQDvOPCD9vxHO4w5GHb8RwODLby8NrtR2dpLHPvWnc1OBwYrLtf9uk9qE/3Lh9yOO6Ij7iRRU5YcHXP5zhfF8dcXju+8ytPObq/o07UdNSiVljE657vQdeI6XCXi2Ow7ngOBwbrzmYfzoBVn+7Bg3V+h4H/3W2GuzcNd9V42pi8X1nPcnBzcz7gjHVrdwbiZ5ZzKpd93VrPZh7yAYNVXHM4f8cBt7M4E5Z5jPF6dhZza817zq/rEY99vNYcuh9x2detK9/Ix37mMa413bnXmvhs9nVrvQ/mIRcwWMWx11zANQ74Dp9ju3jF9fxuz3itZ/vVWrQejtMzOh/n0JjZnnNyHsVHe5wBy1zGeD07i7m15j3n1/WIx75urXUxD2cBg1Vcczh/xwE39h8/M9y9cbhDg1aTa6OzjxtVebrv4hjX87oceq7jMcet9SzmOJ87gzHEwCIfcwpze8Soz/GRd2SRB1a5OM/hivGe47rczMea44DBjnzgODuKc77CNA9jiIEFlzmF6R68u63Wyec7n6ubMcTAIh9zCtP9CEMutpzX4fCPrKsBfOTEni18Gg+8uLpWjPPBpxj2eg5wxHV+1KB+4BoPHvv5LPAVm+05r+N25yHOxRTGcTMu5+A4xjUnfC43Y8gH28VxDJ+lcV088Nj827IXjnX/TP3HH3/8hxfdJzUeHjq1X+0e9ZfKE+tXjbF/pVbkUPtKzq8Uq/eN/Ve6h91aca9qd/PdEVe13nHO7hlPr6/uSz9v7Hfv+V1xX0Hrd2mDc/MndxeOeJ8+3KGJYv/1H46MFtEiPZAeSA+kB97dAxnuMtw9+tvwux+QnJ9f0umB9EB6ID3w1Xogw12Guwx3L/6fDL7aQ59686JKD6QH0gOf3QMZ7jLcZbjLcJceSA+kB9ID6YEP6oEMdxnu8kB/0AOdb+Of/W08n28+3/RAemClBzLcZbh71HCXfwvq919cX02Pr1bvyi/JcH7vSdXjx9/+tvU7ZDdOz/+K+917340babSbczduVEt842ftiD4Z7j5suLvi5bqbcyduJ+ZIw3817qoeq7wj97+TcyfmSE1XcflFxevZecXFNePCfyQ/Ys60R87HvalFPbNcR+OU3+1x/ortciiuudTf7TWu9o4LXvmwVqtx7B/FMY/Xmg97cLqc4DlbsV0c8saeN6TtapnhLsNd+4sGTbX7wt6J24lBnZ9oV/VY5R3RaCfnTsyRmq7i8suK16PzmFdr3q/GjXhX+VbrrPNn3M5fuPMBg925x6OxR/lHanK5C+uuTtOOD7yLO1IruMgJC3zFVkzxYFdiwnnPoJfh7s3DXb0McelD4HBgsBwDDJZ9tQYOC3/tsYYFBi4s/DMLPqzjO19hymUMMbDgYg8LHBY4LPBdW3kqVi3n687iGKy7OOdnLmrAWR0ffo3t9uDDOp7zFaZcxhADCy72sMDvsPyi4vXsbOXqvotf5XXxr+JHzp9xO7/DCwMOq/cCzshqzGw/ysU+zcM+ty5+4Ro32+/E7J6ltejZule+7sGHVX/27xnknO4Z7t443NWLjD8U3q+sK5Z5bo/8ylMu+3mtPORbsZqHY9jXrfVs5iEXMFjFNYfzAzticZ5a5ABee15jr1gX1/HAhx3x2MdrxHZ2xGVft668Ix/7mcd4V9tZeL2k3LWSv3vBKc57rMti/et+aUjocPA0FjjbWuMCHxb4zHIdjot8jsc+rJHD8cvX4YjbsVfkRB1d7sL5Ar9sFwPfKA4+zre65lisy47i1Y897Cg2vn89f+/SIsPdm4Y7fZlxAzgfMFjwZ/uOVzjHdmvlId+K5ZzMdzgwWHcu+5APGKziLg84r1icp7Y7D7zO3+EcN6q34zncYS53x3M4MFh3P+zDecBgFcf+KlsvKrysYI+cxfGI0zy8Z76uK95himOP87Dnc+BjjHPDP7IcCx7ncH7wRraL6/BRrplvJ2fFHLm4BnceY7w+I45z8FrrZx/WXS2dH3zODW7s+4c5/Qwy3H2j4a5eoHpxQ8DHWK31xav+bt/FORyYWs5dPne5GpEH8YjD/lWL/GpdLYohRmtwuMM0TvOz38U7jGOw7ngOB6YWucqWz13wKZf3V63xwvpVw+RPMroa8LKDn3NqXva5Nedy/pUzwHFnc07muTVqYcs8l4u5ozXnwXrEZx/4K5bjRuuVXMypXLzHWnG3Rx2IKet4Iz/7rlpzTd36qrOT9/VhMcPdNxruZg8MXrzKwwtb8dm+i3M4sLK4ND84itdefbpHTJcb/lWL/GpdLYohRs9yuMM0TvOz38U7jGOw7ngOB1YWF/LAgoM9W/XpnrlnrPGCdXaUn19yzAMOCx/veV1+3tcae14rbyWv43R5wD1qUesoznEc1uU4wu1yKH5FTj6j8vOlPt7zmmO0Rt1zXLfWfG7fxRauZ2IPO4qN7/XB7AwNM9xluPv1DZRfprz+9aDLPxu42niaB3EOBwbrzmUfcsGqT/fgwc784I0scsCCq/vCGeM1YpQDvOPCD9vxHO4w5GHb8RwODLby8NrtR2dpLHPPWvOLitej/B0POCxy8J7X5ed9rbHntfJW8jpOlwdcZ1HPUR/4Lt5h4Ks9wtXYbr+Sc4XT5QfucjhsxF/xgXPUjmqpXOzv1kfPDP/eoS/D3ZuGu18PkAxN/EJbWc9y8MPE+YAz1q3dGYifWc6pXPZ1az2becgHDFZxzeH8HQfczuJMWOYxxuvZWcytNe85v65HPPbxWnPofsRlX7eufCMf+5nHuNZ05n7npcUxqIUxXevexRTW8dS3sndnVH4+A5yRPcrnXF1sh3Ms1ke4iJnZlZwrnCPnVD5cXdwZZ2punOmscnXvYoApN/t7h7ZVvTPcvXG4qw+pXmq49ENz+MpL0MXpWZyH16hBsS4n+J0dxTmfnou6kR8xsIxjrTHYI2Z2BucZrZEHVrk4z+GK8Z7jutzMx5rjgMGOfOA4O4pzvsI0D2OIgQWXOYXpHryzbL2okIvXwEYWLzlY5gKDha/2tVbcYeByLOKcDzy1HKNxytW9xupe+bp353WY5h7t9Ry3H8U7H+dwfocdiSlu5eAYXrv8ijF/ZT06z8WvnHc0pzsn2H2DYIa7Nw93X7nZ8YJW+9Xu6epB4gw9VGPsX8mNHGpfyZnY+355fzWtv/NwcPe967Dm9kf75+57OFpf+L//7slwl+Gu/UaZh+X3hyV6RI/0QHogPZAe+Ao9kOEuw12GO/oPvn6FhzY15uWSHkgPpAfSA6MeyHCX4S7DXYa79EB6ID2QHkgPfFAPZLjLcJcH+oMe6NE3ufjyTT89kB5ID3yPHshwl+Euw12Gu/RAeiA9kB5ID3xQD2S4y3CXB/qDHuh8K/8e38rzOedzTg+kB0Y9kOEuw12Guwx36YH0QHogPZAe+KAeyHB34XD397///edff/2VB+aDHpjRN6X48k06PZAeSA+kB57QAxnuLhzu/vzzz5814P3xxx+5okF6ID2QHkgPpAfSA7f0QIa7C4e7pI4CUSAKRIEoEAWiwN0KZLi7W/GcFwWiQBSIAlEgCkSBCxXIcHehuEkdBaJAFIgCUSAKRIG7Fchwd7fiOS8KRIEoEAWiQBSIAhcqkOHuQnGTOgpEgSgQBaJAFIgCdyuQ4e5uxXNeFIgCUSAKRIEoEAUuVCDD3YXiJnUUiAJRIApEgSgQBe5WIMPd3YrnvCgQBaJAFIgCUSAKXKhAhrsLxV1J/ePHj5+4Vvh3c6q2lZ9V3kquKzldnfgMOntlTau5u9oYX811NW9WU/ndz26cy8VYdx5zVtaz+lZyhBMFokAUuFoB/xv26lOT/98VGL10dnz88tH4HZ/mQOGaa8RDzFnWneXqAcbndrHMcWsX9yoP9XXW5Z9hXZ0dPss38nc5Fdd95VzBVjjIVVy9uHaXi/1uPYoZ+VyuYFEgCkSBOxXIcHen2uas0Uui8xXufCPsTJ+5DVtP8dy5Lv4I9kpOF+swrWeFs3q/q7m0BuSv+O5yMYjrfLu4uw+HufOVp3vUpPhsjzi1Gqd+tx/FjHwuV7AoEAWiwJ0KZLi7U21z1uglcdTn+MBguQRgsKs+5mHtcpSvwxG3Y7uciuu+q8fxtK4VTpd/N9dZcat16XmzvdPEYe585ekeZxeuF3wuL/t43eVnjq5HMSOf5sk+CkSBKHC3Ahnu7lZcztt9Sbi4VQwlgA8LvCwwWPbBXz6+lHP3XmvVPep2dfF9uLWLUQznwaofe5ffYeCzdTzFmP+OddXDP7ovn2K6R7zisz3i1Gqc+o/uz8539Pzwo0AUiAIjBX7/LTxixneJArsvCRe3ghUHF25oFOd8iGO7yuOYs9dag+7rvMJwnXW+y+cwnFe+T//B/Xf36nDFdF+aKab7Ttfi4eo4R/DVc4/kDDcKRIEocJYCn/+WOUupi/LsviS6OLzAYEdlIwcscxlDLmcRw3xgd1utQfdVj8N266xcs3yOM4tx9SDPqnU5vgLG9+fqVe1072IKW+V18YqfnU/zZx8FokAUeEWBDHevqHdC7O5LwsWtYiib+bXWC7wVy7lW+FdwtAbd15mK1f7IdVbdK2eeddbdefTecD7jwI7aysE/umcfr1d5HDNan51vdFZ8USAKRIGjCvz+m/JodPgvK7D7knBxqxiKdvwVHzhsR7mYd+Vaa9B9ne0wV9Mqz8VehVVNs+uqs1/J67R02M4Zq3lWeas1nJ1v9dzwokAUiAIrCmS4W1HpQs7uS8LFjbCRz90e83ntuE/BtE7dV50Oc/Wv8lzsO7Gn1F114HJ6jOp0PodV3g7XM1d5Gtftz87XnRM8CkSBKLCjQIa7HdVOjNl9Sbi4Ebbrq1t1sWdIcEVe5ITVOjt8l6dxV++r/tG1c/6qJqu5V/KNOM7nsKqnw7XWjtfhGq/73TjNk30UiAJR4AoFMtxdoeqBnLsviS6ucL64FMY1fubjPGettYZX8mr9ukfu1TNnPM0/2/P5My77EVe28Ct+zs67kq/jAIfl+2aMdSi8u8AbxYJzxHb5juQINwpEgShwlQLXvC2uqvYD8/JL6cm3x3V26yP1v+vluHruKu/IPZ/B7bRn/Mg5V90n14M116XndpwVHuft1pqn481w1HlWvtl58UeBKBAFdhTIcLejWmKiQBSIAlEgCkSBKPBQBTLcPfSDSVlRIApEgSgQBaJAFNhRIMPdjmqJiQJRIApEgSgQBaLAQxXIcPfQDyZlRYEoEAWiQBSIAlFgR4EMdzuqJSYKRIEoEAWiQBSIAg9VIMPdQz+YlBUFokAUiAJRIApEgR0FMtztqJaYKBAFokAUiAJRIAo8VIEMdw/9YFJWFIgCUSAKRIEoEAV2FMhwt6NaYqJAFIgCUSAKRIEo8FAFMtw99INJWVEgCkSBKBAFokAU2FEgw92OaomJAlEgCkSBKBAFosBDFchw99APJmVFgSgQBaJAFIgCUWBHgQx3O6olJgpEgSgQBaJAFIgCD1Ugw91DP5iUFQWiQBSIAlEgCkSBHQUy3O2olpgoEAWiQBSIAlEgCjxUgQx3D/1gUlYUiAJRIApEgSgQBXYU+Jjh7v/8t//0E9eOEByDPGXzEwWiQBSIAlEgCkSBr6TAW4Y7DE9nCjUaxDof6oDVero45b26//HDfwyF43r1jO8S32mp97/K07jsf/7qSacDerWzLubTsU4Lxr+SBrO6y/+En6vqfMr9HdV4psfRfMy/Mjefc/d6dl9P74Xbn0QemHg9++Bm3M5fuPOtYI4zq/Oof9Qgu76VGrrchfPFuRjX+JGvciif8+6uXU6H4fxZjeDt1tPFdTV1fMVfjdd8tXc5VR/ec44uljlu7eJe5XGNbv1KfhfbYav35uK72A53OVaxV3JqrDjOFw4AAAeBSURBVO6rBoeN8NW6HW/1LMfrsML14rNd3N33x/W4dVfj3XWOdHR1r2Bn59R82HMthXU/I18XcxfeV31BBW5Ycpg7esYb+Z1vBXMc1DbygbNiR82x65udW3ld7hG260MtLh6+XetyOszl73gd7nKsYq/mfDXe1flKThfrMD13hVMxK7wVjp6P/SuxyKF2lLN8o0tzYT/KCc5Ru5uzi1Nc96ivw+HfsS6nwyq34rN9V4/Ggdfh8O/Y3ZyjuJFvp8aKcTlXsSNn3pVTa3LngjPygfMu+5jhzg1LwMry5cQCd9Xn+IrpnnOPfMwbrWeNMfKPfKMz4XPxI2zXNzoPvl07qmmW08VWTIfP8o38r+Z8Nd7V1uVUXPedRo6n565wuvy7uTRuNb+LG2HdvXX4KBd8r8Qih9rdnF2c4rrH+R0O/451OR1WuQvXi8/s4piDPIqNcMddxVZr0nyjuJFP86zuXc5VbPWM4t2VU2ty5zJn5mfunesvMdyVILNhauR3vhXMcc78cGZNMfO/UovLvYrhXPBhgZd1GPuvWnfnFq7XVTV85byqn+7r3hwGXDXm/YouyA3bxXDe0bqLvxMf1QffnfXsnlW18o/uy+cwjrl63Z2v+Gzf1alxHe+p+BX1u5yr2Ks6uXOO5FyJn3Fm/iP1nMn9/Wk9M7PJ5YYlYLAcxhivmYP1yN/5CucLuWC7OPhftbOmmPlfOd/lXsGKgwvnr8SBe7V1tbgzV3ku9pMx1UX3de+F4TpLC5fPYTivfPm5XwF8Jp3+HX5npVqD7qsWxXTf1Vs8XB3nyfjqfR65B5dzFTtyjnLdGcqZ7SuHXhozO2fm13x37W/9DemGJWCwfOOM8Zo5WI/8zreCOQ7OO8POmmLmf6WGLnfhfI3OQA5Y5jqM/VeuuX5d49x31ocanmhVF91XzQ7bvZfKNcvnOLOY3XrOjEPdq/bMs797LtbcaaH9o3sXU9gqr4t/N35F/S7nKrarh8u/k8vlUUz3es7Mr/y79hnuSGkd5nRP1OlfEzO3W8+aYubv8q7gLvcqhvzMr7Ve4D3Rcu1PrO9dNakuuq+6FKv9keuse1s586yzkuefnztrDk0cBt9TbdXMP7pnH69XeRzzpPUV9bucq9iONi73Tp4uRvPrXuNmfuXftf+9wy8+1Q1LwGC5BMZ4zRysR37nW8EcZ+U8cGZ21hQz/yz/yO9yr2LI6/grPnDeaUe1v7Oud5+tuui+6nOYq3uV52I/BSsNZtdXvVf3+TrsK9zfat2rvKfe8xX1u5yr2FGdXN6jOWZ8PUP3Gj/zK/+u/a3DXd0UD0zdGryRXwVi7orP8RXTveZ9dT9ripn/lfNd7hE28rk6HN/xrsDeefYV93NnTtVO91WLw1yNqzwX+52wr6RT1YrLfUZPuhdXi8PqPjpc73GVp3FP2V9Rv8u5ih3RxeU8Eu+4Lqdiutc8M7/y79rfPtzVjdXQ5AYn4PDBQgz4sWer3BUf8sFyTK1HOZW7ux81xsi3ex7iXO4RtuvDeSPrco/4M9/Z+XDeVXmRf8deURNywmpdHb7L07h37lfv7UiNlXN0HckF7hV1IndnV85c4Wj+nRjN4fYur8MqtsM17yqP43ZiON6td3OO4kY+VwMwF7eCOQ5yOrvCX+FwbsdXTPezePa/c/2W4e6KG8aAdsZAdmau2b2+q3G6cwvni+tnXONHPs7h1prLcY5gZ+fD2VflRf4de2ZNlWt0ob7VM2e80VnOx+c7f4chbsVWjjN/zs6H2q7Ki/zOrpy5wtHcOzGaQ/fICVt+rGFdTPncBW4XC7+zOzEuD2O7OUdxIx+fresurnC+VuOUhz3n4jX8ZQs/+sO5XLzDcMbIB8677HEl3lXpB5/bNUjhuD719rt7f/V+odvIHjnjqjqP1KDcd9W0eu4qT+/rXfur6q28s+vIPV9V50oN7j447mhtR/l8llujPvatYhzTrY/We5TfnfsqDg26ejp85dxZbpfjlfNcvsLOzjm7r7PP6+5rF89wt6vcw+K4Ebv1w0r+tuV0nw/j31ac3PitCnDPdetbC8phUSAKnKJAhrtTZEySKBAFokAUiAJRIAo8Q4EMd8/4HFJFFIgCUSAKRIEoEAVOUSDD3SkyJkkUiAJRIApEgSgQBZ6hQIa7Z3wOqSIKRIEoEAWiQBSIAqcokOHuFBmTJApEgSgQBaJAFIgCz1Agw90zPodUEQWiQBSIAlEgCkSBUxTIcHeKjEkSBaJAFIgCUSAKRIFnKJDh7hmfQ6qIAlEgCkSBKBAFosApCmS4O0XGJIkCUSAKRIEoEAWiwDMUyHD3jM8hVUSBKBAFokAUiAJR4BQFMtydImOSRIEoEAWiQBSIAlHgGQpkuHvG55AqokAUiAJRIApEgShwigIZ7k6RMUmiQBSIAlEgCkSBKPAMBTLcPeNzSBVRIApEgSgQBaJAFDhFgQx3p8iYJFEgCkSBKBAFokAUeIYCGe6e8TmkiigQBaJAFIgCUSAKnKJAhrtTZEySKBAFokAUiAJRIAo8Q4EMd8/4HFJFFIgCUSAKRIEoEAVOUeD/A+xEAYf7J8sLAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "reasonable-flooring",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "14번째 어절이 시작하는  토큰 인덱스를 구하고, 답이 끝나는 어절이 마지막 어절이 아니라면, {다음 어절(15번째 어절)이 시작하는 토큰} 직전에 등장하는 토큰의 인덱스를 구한다. 만약 마지막 어절이라면, 마지막 토큰 인덱스를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "checked-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 20, ['▁교향곡', '을'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start = word_to_token[word_start]\n",
    "if word_end < len(word_to_token) - 1:\n",
    "    token_end = word_to_token[word_end + 1] - 1\n",
    "else:\n",
    "    token_end = len(context_tokens) - 1\n",
    "token_start, token_end, context_tokens[token_start:token_end + 1] # token_end를 포함하도록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-cylinder",
   "metadata": {},
   "source": [
    "tokenized 기준 대략적인 위치 [19, 20]로 특정되었다. 이제 답 역시 같은 방식으로 tokenize하고 정확한 위치인 new_start와 new_end를 탐색한다. 이제 정확히 일치하는 위치를 찾을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "descending-florida",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁교향곡'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 정답인 answer_text도 Subword 기준으로 토큰화해 둡니다. \n",
    "token_answer = \" \".join(vocab.encode_as_pieces(answer_text))\n",
    "token_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recent-excitement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X >> (19, 20) ▁교향곡 을\n",
      "O >> (19, 19) ▁교향곡\n",
      "X >> (20, 20) 을\n"
     ]
    }
   ],
   "source": [
    "# 정답이 될수 있는 new_start와 new_end의 경우를 순회탐색합니다. \n",
    "for new_start in range(token_start, token_end + 1):\n",
    "    for new_end in range(token_end, new_start - 1, -1):\n",
    "        text_span = \" \".join(context_tokens[new_start : (new_end + 1)])\n",
    "        if text_span == token_answer:   # 정답과 일치하는 경우\n",
    "            print(\"O >>\", (new_start, new_end), text_span)\n",
    "        else:\n",
    "            print(\"X >>\", (new_start, new_end), text_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-russian",
   "metadata": {},
   "source": [
    "함수로 정리하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "graphic-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_tokens에서 char_answer의 위치를 찾아 리턴하는 함수\n",
    "def _improve_span(vocab, context_tokens, token_start, token_end, char_answer):\n",
    "    token_answer = \" \".join(vocab.encode_as_pieces(char_answer))\n",
    "    for new_start in range(token_start, token_end + 1):\n",
    "        for new_end in range(token_end, new_start - 1, -1):\n",
    "            text_span = \" \".join(context_tokens[new_start : (new_end + 1)])\n",
    "            if text_span == token_answer:\n",
    "                return (new_start, new_end)\n",
    "    return (token_start, token_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "joined-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_start: 19  token_end: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁교향곡']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start, token_end = _improve_span(vocab, context_tokens, token_start, token_end, answer_text)\n",
    "print('token_start:', token_start, ' token_end:', token_end)\n",
    "context_tokens[token_start:token_end + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-moldova",
   "metadata": {},
   "source": [
    "일련의 과정을 하나로 묶어 훈련과 검증 데이터셋에 적용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "empty-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_korquad(vocab, json_data, out_file):\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for data in tqdm(json_data[\"data\"]):\n",
    "            title = data[\"title\"]\n",
    "            for paragraph in data[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                context_words, char_to_word = _tokenize_whitespace(context)\n",
    "\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    assert len(qa[\"answers\"]) == 1\n",
    "                    qa_id = qa[\"id\"]\n",
    "                    question = qa[\"question\"]\n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    answer_start = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    answer_end = answer_start + len(answer_text) - 1\n",
    "\n",
    "                    assert answer_text == context[answer_start:answer_end + 1]\n",
    "\n",
    "                    word_start = char_to_word[answer_start]\n",
    "                    word_end = char_to_word[answer_end]\n",
    "\n",
    "                    word_answer = \" \".join(context_words[word_start:word_end + 1])\n",
    "                    char_answer = \" \".join(answer_text.strip().split())\n",
    "                    assert char_answer in word_answer\n",
    "\n",
    "                    context_tokens, word_to_token = _tokenize_vocab(vocab, context_words)\n",
    "\n",
    "                    token_start = word_to_token[word_start]\n",
    "                    if word_end < len(word_to_token) - 1:\n",
    "                        token_end = word_to_token[word_end + 1] - 1\n",
    "                    else:\n",
    "                        token_end = len(context_tokens) - 1\n",
    "\n",
    "                    token_start, token_end = _improve_span(vocab, context_tokens, token_start, token_end, char_answer)\n",
    "\n",
    "                    data = {\"qa_id\": qa_id, \"title\": title, \"question\": vocab.encode_as_pieces(question), \"context\": context_tokens, \"answer\": char_answer, \"token_start\": token_start, \"token_end\":token_end}\n",
    "                    f.write(json.dumps(data, ensure_ascii=False))\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "opponent-divide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ea4be1db334b5c81e8569cdc9bc39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d0be03e5254ce2a02d233c63d9a6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전처리를 수행하여 파일로 생성합니다. \n",
    "dump_korquad(vocab, train_json, f\"{data_dir}/korquad_train.json\")\n",
    "dump_korquad(vocab, dev_json, f\"{data_dir}/korquad_dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-cliff",
   "metadata": {},
   "source": [
    "잘 나온 것을 확인했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-typing",
   "metadata": {},
   "source": [
    "### abnormals and missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-feelings",
   "metadata": {},
   "source": [
    "question의 길이의 분포를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "secret-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ['▁바그너', '는', '▁괴테', '의', '▁', '파우스트', '를', '▁읽고', '▁무엇을', '▁쓰고', '자', '▁', '했', '는', '가', '?']\n",
      "168 ['▁바그너', '는', '▁교향곡', '▁작곡', '을', '▁어디', '까지', '▁쓴', '▁뒤에', '▁중단', '했', '는', '가', '?']\n",
      "80 ['▁바그너', '가', '▁', '파우스트', '▁서', '곡을', '▁쓸', '▁때', '▁어떤', '▁곡', '의', '▁영향을', '▁받았', '는', '가', '?']\n",
      "6 ['▁1839', '년', '▁바그너', '가', '▁교향곡', '의', '▁소재로', '▁쓰', '려고', '▁했던', '▁책은', '?']\n",
      "143 ['▁', '파우스트', '▁서', '곡', '의', '▁라', '단', '조', '▁조성', '이', '▁영향을', '▁받은', '▁베토벤', '의', '▁곡은', '?']\n",
      "0 ['▁바그너', '가', '▁', '파우스트', '를', '▁처음으로', '▁읽', '은', '▁', '년', '도', '는', '?']\n",
      "165 ['▁바그너', '가', '▁처음', '▁교향곡', '▁작곡', '을', '▁한', '▁장소', '는', '?']\n",
      "216 ['▁바그너', '의', '▁1', '악장', '의', '▁초연', '은', '▁어디서', '▁연주', '되었', '는', '가', '?']\n",
      "164 ['▁바그너', '의', '▁작품을', '▁시인', '의', '▁피로', '▁쓰여', '졌다', '고', '▁극찬', '한', '▁것은', '▁누구', '인', '가', '?']\n",
      "7 ['▁잊', '혀', '져', '▁있는', '▁', '파우스트', '▁서', '곡', '▁1', '악장', '을', '▁부활', '시킨', '▁것은', '▁누구', '인', '가', '?']\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "token_starts = []\n",
    "with open(f\"{data_dir}/korquad_train.json\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        questions.append(data[\"question\"])\n",
    "        contexts.append(data[\"context\"])\n",
    "        token_starts.append(data[\"token_start\"])\n",
    "        if i < 10:\n",
    "            print(data[\"token_start\"], data[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "higher-mailman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 14, 16, 12, 16, 13, 10, 13, 16, 18]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token count\n",
    "train_question_counts = [len(question) for question in questions]\n",
    "train_question_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "piano-document",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_question_counts, bins=100, range=[0, 100], facecolor='b', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Count of question')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of question')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of question')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bottom-grocery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 길이 최대:      58\n",
      "question 길이 최소:       3\n",
      "question 길이 평균:      15.25\n",
      "question 길이 표준편차:    5.50\n",
      "question 25/100분위:    11.00\n",
      "question 50/100분위:    14.00\n",
      "question 75/100분위:    18.00\n",
      "question IQR:           7.00\n",
      "question MAX/100분위:   28.50\n"
     ]
    }
   ],
   "source": [
    "# 데이터 길이\n",
    "print(f\"question 길이 최대:    {np.max(train_question_counts):4d}\")\n",
    "print(f\"question 길이 최소:    {np.min(train_question_counts):4d}\")\n",
    "print(f\"question 길이 평균:    {np.mean(train_question_counts):7.2f}\")\n",
    "print(f\"question 길이 표준편차: {np.std(train_question_counts):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(train_question_counts, 25)\n",
    "percentile50 = np.percentile(train_question_counts, 50)\n",
    "percentile75 = np.percentile(train_question_counts, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"question 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"question 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"question 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"question IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"question MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "competent-aging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAFlCAYAAADriV2xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVT0lEQVR4nO3df3BdZZ3H8ffHtiY0SEu22bTLD9MRRyuBBY2OIqtU+eGqU5hZR9dRp9VMOnR3Mu6wYKH5Y9Wx3bIiuuuMRjC63Vkm6LJKGOq6W9nA2mVXJ1WgQEdBKAakbdimIOkWUvjuHzntpjXn5ja5N4d7n89r5s4957nn3vNNp/nc53nOjygiMLN0varoAsysWA4Bs8Q5BMwS5xAwS5xDwCxxDgGzxM0vZyNJi4FvAu1AAJ8CfgF8B2gDdgMfjojRUp+zZMmSaGtrm3GxZjYzO3bseCYiWqZ6TeWcJyBpC/DjiPimpFcDC4ENwP6I2CzpWuDUiFhf6nM6OjpiaGjoxH8CM5sVSTsiomOq16YdDkhaBLwL6AOIiBcj4gBwObAl22wLcEUlijWzuVXOnMByYAT4tqSfS/qmpCagNSKezrbZA7RWq0gzq55yQmA+8Gbg6xFxPjAGXDt5g5gYU0w5rpC0VtKQpKGRkZHZ1mtmFVZOCDwJPBkRP8nWb2MiFPZKWgaQPe+b6s0RcVNEdERER0vLlPMSZlagaUMgIvYAw5LekDW9F3gYuANYnbWtBgaqUqGZVVVZhwiBbuCW7MjAY8AnmQiQ70rqBJ4APlydEs2smsoKgYi4D5jq8MJ7K1qNmc05nzFoljiHgFniHAJWUn9/P+3t7cybN4/29nb6+/uLLskqrNyJQUtQf38/PT099PX1ceGFF7J9+3Y6OzsB+OhHP1pwdVYpZV07UCm+dqC2tLe389WvfpWVK1cebRscHKS7u5sHH3ywwMrsRJW6dsAhYLnmzZvHoUOHWLBgwdG28fFxGhsbeemllwqszE7UrC4gsnStWLGC7du3H9O2fft2VqxYUVBFVg0OAcvV09NDZ2cng4ODjI+PMzg4SGdnJz09PUWXZhXkiUHLdWTyr7u7m127drFixQo2btzoScE64zkBswR4TsDMcjkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BKyk7u5uGhsbkURjYyPd3d1Fl2QV5hCwXN3d3fT29rJp0ybGxsbYtGkTvb29DoI642sHLFdjYyObNm3iqquuOtp24403smHDBg4dOlRgZXaifFMRmxFJjI2NsXDhwqNtBw8epKmpibn8f2Oz5wuIbEYaGhro7e09pq23t5eGhoaCKrJqcAhYrq6uLq655hqWLl2KJJYuXco111xDV1dX0aVZBTkELNcFF1xAU1MT+/fvB2D//v00NTVxwQUXFFyZVZJDwHJt3LiRgYEBXnzxRSKCF198kYGBATZu3Fh0aVZBnhi0XL7bcP3wxKDNiO82nAaHgOXy3YbT4LsNWy7fbTgNnhMwS4DnBMwsl0PALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLXFmXEkvaDfwWeAk4HBEdkpqB7wBtwG7gwxExWp0yzaxaTqQnsDIizpt0OeK1wF0R8Xrgrmzd6kx/fz/t7e3MmzeP9vZ2+vv7iy7JKmw2NxW5HLgoW94C3A2sn2U99grS399PT08PfX19XHjhhWzfvp3Ozk4A31ikjpTbEwjg3yTtkLQ2a2uNiKez5T1Aa8Wrs0Jt3LiRvr4+Vq5cyYIFC1i5ciV9fX2+23CdKevOQpJOi4inJP0+sA3oBu6IiMWTthmNiFOneO9aYC3AmWee+ZYnnniiUrVblfluw/Vj1ncWioinsud9wPeBtwF7JS3LdrAM2Jfz3psioiMiOlpaWmZSvxXEdxtOw7RzApKagFdFxG+z5UuBzwN3AKuBzdnzQDULtbnX09PD5ZdfzqFDhxgfH2fBggU0NjbyjW98o+jSrILK6Qm0Atsl3Q/8FNgaET9k4pf/EkmPABdn61ZH7r33XsbGxmhubkYSzc3NjI2Nce+99xZdmlWQ7zZsuRobG9m0aRNXXXXV0bYbb7yRDRs2cOjQoQIrsxNVak7AIWC5JDE2NsbChQuPth08eJCmpibm8v+NzZ5vOW4z0tDQQG9v7zFtvb29NDQ0FFSRVYNDwHJ1dXVx9dVXM3/+fCQxf/58rr76arq6uoouzSrIIWCWOIeA5br55pu54YYbOHz4MBHB4cOHueGGG7j55puLLs0qyBODlssTg/XDE4M2I54YTIP/NLnl6urqYv36iQtDr7zySnp7e1m/fj1XXnllwZVZJXk4YCWdeeaZDA8PH10/44wz+PWvf11gRTYTHg7YjFx22WUMDw+zbt06Dhw4wLp16xgeHuayyy4rujSrIA8HLNe2bdtYt24dX/va1wCOPh8/T2C1zcMByyWJAwcOsGjRoqNtzz77LIsXL/bRgRrj4YDNiCSuu+66Y9quu+46JBVUkVWDhwOW65JLLuHrX/86t956KwcOHGDx4sWMjo5y6aWXFl2aVZB7ApZrzZo1nHTSSYyOjhIRjI6OctJJJ7FmzZqiS7MKcghYro0bN7J161Yi4uhj69atvtFonfHEoOXyjUbrhycGbUZ8o9E0OAQsV09PD52dnQwODjI+Ps7g4CCdnZ309PQUXZpVkIcDVpJPG64PHg7YjJx77rkMDw+zatUqRkZGWLVqFcPDw5x77rlFl2YV5BCwXDt37mTVqlUMDAywZMkSBgYGWLVqFTt37iy6NKsgh4CV1NfXV3Ldap9DwEo68leI89at9vm0Yct1zjnncMcdd/zOtQLnnHNOQRVZNbgnYLmeeuqpE2q32uQQsFz79+/n7LPPPua04bPPPpv9+/cXXZpVkEPASvrBD35Qct1qn0PASnr/+99fct1qnycGLVdzczMPPfTQ70wMNjc3F1SRVYN7ApbrhRdeOKF2q00OAcs1NjZGW1vbMRODbW1tjI2NFV2aVZBDwEr60Y9+VHLdap9DwEq6+OKLS65b7XMIWK6mpiZ2797N8uXL+dWvfsXy5cvZvXs3TU1NRZdmFeSjA5br+eefRxK7d+/mrLPOOqbd6od7Apbr5JNPBqCtrY1HH32Utra2Y9qtPrgnYLmOHB14/PHHAXj88cePDgmsfrgnYCX56ED9cwhYST46UP88HLBcR44OHH/asI8O1Bf3BMwS5xCwXD5tOA0OASvJE4P1zyFgJXlisP6VHQKS5kn6uaQ7s/Xlkn4i6VFJ35H06uqVaUXwacNpOJGewKeBXZPWrwe+HBFnAaOA70VdZ46cHnzktOEjJwn5tOH6UlYISDod+ADwzWxdwHuA27JNtgBXVKE+K1BjYyMAra2t7Nq1i9bW1mParT6Ue57AV4DPAK/J1n8POBARh7P1J4HTKluaFe2FF16gtbWVPXv2ALBnzx6WLl3K3r17C67MKmnanoCkDwL7ImLHTHYgaa2kIUlDIyMjM/kIK9Ddd99dct1qXznDgXcCqyTtBm5lYhjwt8BiSUd6EqcDU/5Fioi4KSI6IqKjpaWlAiXbXLroootKrlvtmzYEIuK6iDg9ItqAPwX+PSI+BgwCH8o2Ww0MVK1KK0RDQwN79+5F0tHH3r17aWhoKLo0q6DZnCewHrhK0qNMzBH4z9XWGd9tOA0ndAFRRNwN3J0tPwa8rfIl2StNRBxdPv5iIqt9PmPQSrr99ttLrlvt0+SUr7aOjo4YGhqas/3Z7Bz51p+qJzCX/29s9iTtiIiOqV7z/QRsWh4C1DcPB8wS556ATcsTg/XNPQEryROD9c8Tg5bLE4P1o9TEoHsCNi1JDAwMeChQpxwClmvyt/0VV1wxZbvVPoeA5Zr8zb9+/fop2632OQRsWhHB5s2b3QOoUw4BK2lyD2Cqdat9PjpguXx0oH74tGGbFc8B1DcPB8wS556ATcunDdc39wSspK6urpLrVvs8MWi5PDFYPzwxaLPiIUB983DALHHuCdi0PDFY39wTsJI+9rGPlVy32ueJQcvlicH64fsJ2KxI4uMf/7iHAnXKIWC5Jn/b33LLLVO2W+1zCFiuyd/87373u6dst9rnowM2LR8dqG/uCVhJk3sAU61b7XMIWEn33HNPyXWrfR4O2LQ8BKhv7gmYJc49AZuWJwbrm3sCVtIpp5xSct1qn0PASnruuedKrlvtcwjYtCSxaNEiDwXqlEPAck2eC5jcA/Bpw/XFIWC58r753SOoLz46YNPy0YH65p6AWeIcAmaJ83DApuUhQH1zT8Asce4J2LQ8MVjf3BMwS5xDwCxx04aApEZJP5V0v6SHJH0ua18u6SeSHpX0HUmvrn65VgRJRx9Wf8rpCbwAvCci/hA4D3ifpLcD1wNfjoizgFGgs2pVmlnVTBsCMeH5bHVB9gjgPcBtWfsW4IpqFGjFi4ijD6s/Zc0JSJon6T5gH7AN+BVwICIOZ5s8CZyW8961koYkDY2MjFSgZDOrpLJCICJeiojzgNOBtwFvLHcHEXFTRHREREdLS8vMqjSzqjmhowMRcQAYBN4BLJZ05DyD04GnKluavVJ4YrC+lXN0oEXS4mz5JOASYBcTYfChbLPVwECVarSC5M0BeG6gvpRzxuAyYIukeUyExncj4k5JDwO3SvoC8HOgr4p1WgFK3U/AQVA/pg2BiHgAOH+K9seYmB+wOufThuubzxg0S5xDwCxxvorQpuUhQH1zT8By+ehAGtwTsJL8C1//HAIGVK7L79CoPQ4BA6b/5fW5AfXLcwJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCVu2hCQdIakQUkPS3pI0qez9mZJ2yQ9kj2fWv1yzazSyukJHAb+MiLeBLwd+HNJbwKuBe6KiNcDd2XrZlZjpg2BiHg6In6WLf8W2AWcBlwObMk22wJcUaUazayKTmhOQFIbcD7wE6A1Ip7OXtoDtOa8Z62kIUlDIyMjs6nVzKqg7BCQdDLwz8BfRMRzk1+LiABiqvdFxE0R0RERHS0tLbMq1swqr6wQkLSAiQC4JSK+lzXvlbQse30ZsK86JZpZNZVzdEBAH7ArIm6c9NIdwOpseTUwUPnyzKza5pexzTuBTwA7Jd2XtW0ANgPfldQJPAF8uCoVmllVTRsCEbEdUM7L761sOWY213zGoFniHAJmiXMImCXOIWCWOIeAWeIcAolobm5G0owfwKzeL4nm5uaC/xVsKuWcJ2B1YHR0lImzu4tzJEzslcU9AbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnELBpjRwcYc0P1/DM/z5TdClWBQ4Bm1bvA738bO/P6L2/t+hSrAocAlbSyMERBh4dIAhuf/R29wbqkEPASup9oJeX42UAXo6X3RuoQw4By3WkFzD+8jgA4y+PuzdQhxwClmtyL+AI9wbqj0PAct2/7/6jvYAjxl8e57599xVTkFWF7yxkuW5bdVvRJdgccE/ALHEOAbPEeTiQiPirU+Czi4qvwV5xHAKJ0Oeee0XcbTg+W2gJNgUPB8wS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5wvJU6IpEL3f+qppxa6f5uaQyARs72XgKTC70dg1THtcEDStyTtk/TgpLZmSdskPZI9O+LNalQ5cwJ/D7zvuLZrgbsi4vXAXdm6mdWgaUMgIv4D2H9c8+XAlmx5C3BFZcsys7ky06MDrRHxdLa8B2jN21DSWklDkoZGRkZmuDszq5ZZHyKMidmi3BmjiLgpIjoioqOlpWW2uzOzCptpCOyVtAwge95XuZLMbC7NNATuAFZny6uBgcqUY2ZzrZxDhP3AfwFvkPSkpE5gM3CJpEeAi7N1M6tB054sFBEfzXnpvRWuxcwK4GsHzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8TNL7oAe2WQVJFtIqIS5dgccggY4F/elHk4YJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4zeXVY5JGgCfmbIdWSUuAZ4ouwmbstRHRMtULcxoCVrskDUVER9F1WOV5OGCWOIeAWeIcAlaum4ouwKrDcwJmiXNPwCxxDoEaIWmxpD8rY7uLJN05FzVVkqQNRdeQKodA7VgMTBsCNcwhUBCHQO3YDLxO0n2SvqgJX5T0oKSdkj5y/BskvVXSzyW9TtJbJN0jaYekf5W0LNvmbknXS/qppF9K+qOpdi5pfbaf+yVtztrOk/Tfkh6Q9H1Jp076zI5seYmk3dnyGknfk/RDSY9I+pusfTNwUvaz3SKpSdLWbF8PTvWzWQVFhB818ADagAcnrf8JsA2YB7QCvwaWARcBdwIXADuAM4EFwL1AS/bejwDfypbvBr6ULb8f+NEU+/7j7P0Ls/Xm7PkB4N3Z8ueBr0z6zI5seQmwO1teAzwGLAIamTh79IzsteeP+9lunrS+qOh//3p++I+P1K4Lgf6IeAnYK+ke4K3Ac8AKJg7pXRoRv5HUDrQD27K/IjQPeHrSZ30ve97BRNgc72Lg2xFxECAi9ktaBCyOiHuybbYA/1RG3XdFxLMAkh4GXgsMH7fNTuBLkq4H7oyIH5fxuTZDDoH69DQT37TnA78BBDwUEe/I2f6F7PklKvN/4jD/P9RszNlX7v4i4peS3sxEz+QLku6KiM9XoC6bgucEasdvgddMWv8x8BFJ8yS1AO8Cfpq9dgD4APDXki4CfgG0SHoHgKQFks4+gX1vAz4paWH2/ubs23x00hzCJ4AjvYLdwFuy5Q+VuY9xSQuyz/8D4GBE/CPwReDNJ1CrnSD3BGpERPyPpP+U9CDwL8BngHcA9wMBfCYi9kh6Y7b9XkkfzLb9FBO/jH+XdePnA18BHipz3z+UdB4wJOlF4AdMzOavBnqzcHgM+GT2lhuA70paC2wt80e8CXhA0s+AfwC+KOllYBxYV+Zn2Az4jEGzxHk4YJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXu/wD70WyD6Ca4HgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라미터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(train_question_counts, labels=['token counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-burlington",
   "metadata": {},
   "source": [
    "context에 대해서도 실시한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dress-surfing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[278, 278, 278, 278, 278, 278, 278, 278, 209, 209]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token count\n",
    "train_context_counts = [len(context) for context in contexts]\n",
    "train_context_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "thrown-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_context_counts, bins=900, range=[100, 1000], facecolor='r', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Count of context')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of context')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of context')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "difficult-soviet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context 길이 최대:    4816\n",
      "context 길이 최소:     108\n",
      "context 길이 평균:     222.84\n",
      "context 길이 표준편차:   97.68\n",
      "context 25/100분위:   169.00\n",
      "context 50/100분위:   199.00\n",
      "context 75/100분위:   248.00\n",
      "context IQR:          79.00\n",
      "context MAX/100분위:  366.50\n"
     ]
    }
   ],
   "source": [
    "# 데이터 길이\n",
    "print(f\"context 길이 최대:    {np.max(train_context_counts):4d}\")\n",
    "print(f\"context 길이 최소:    {np.min(train_context_counts):4d}\")\n",
    "print(f\"context 길이 평균:    {np.mean(train_context_counts):7.2f}\")\n",
    "print(f\"context 길이 표준편차: {np.std(train_context_counts):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(train_context_counts, 25)\n",
    "percentile50 = np.percentile(train_context_counts, 50)\n",
    "percentile75 = np.percentile(train_context_counts, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"context 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"context 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"context 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"context IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"context MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "documented-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(train_context_counts, labels=['token counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-reviewer",
   "metadata": {},
   "source": [
    "Answer에 대해서도 실시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "exciting-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 168, 80, 6, 143, 0, 165, 216, 164, 7]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token count\n",
    "train_answer_starts = token_starts\n",
    "train_answer_starts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bronze-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(8, 4))\n",
    "# histogram 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위, \n",
    "# range: x축 값의 범위\n",
    "# facecolor: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_answer_starts, bins=500, range=[0, 500], facecolor='g', label='train')\n",
    "# 그래프 제목\n",
    "plt.title('Count of answer')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of answer')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Count of answer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "vietnamese-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer 위치 최대:    1124\n",
      "answer 위치 최소:       0\n",
      "answer 위치 평균:      89.01\n",
      "answer 위치 표준편차:   78.21\n",
      "answer 25/100분위:    25.00\n",
      "answer 50/100분위:    74.00\n",
      "answer 75/100분위:   134.00\n",
      "answer IQR:         109.00\n",
      "answer MAX/100분위:  297.50\n"
     ]
    }
   ],
   "source": [
    "# 답변 길이\n",
    "print(f\"answer 위치 최대:    {np.max(train_answer_starts):4d}\")\n",
    "print(f\"answer 위치 최소:    {np.min(train_answer_starts):4d}\")\n",
    "print(f\"answer 위치 평균:    {np.mean(train_answer_starts):7.2f}\")\n",
    "print(f\"answer 위치 표준편차: {np.std(train_answer_starts):7.2f}\")\n",
    "# https://ko.wikipedia.org/wiki/%EB%B0%B1%EB%B6%84%EC%9C%84%EC%88%98\n",
    "# 백분위수(Percentile)는 크기가 있는 값들로 이뤄진 자료를 순서대로 나열했을 때 백분율로 나타낸 특정 위치의 값을 이르는 용어이다.\n",
    "# 일반적으로 크기가 작은 것부터 나열하여 가장 작은 것을 0, 가장 큰 것을 100으로 한다.\n",
    "# 100개의 값을 가진 어떤 자료의 20 백분위수는 그 자료의 값들 중 20번째로 작은 값을 뜻한다. 50 백분위수는 중앙값과 같다.\n",
    "percentile25 = np.percentile(train_answer_starts, 25)\n",
    "percentile50 = np.percentile(train_answer_starts, 50)\n",
    "percentile75 = np.percentile(train_answer_starts, 75)\n",
    "percentileIQR = percentile75 - percentile25\n",
    "percentileMAX = percentile75 + percentileIQR * 1.5\n",
    "print(f\"answer 25/100분위:  {percentile25:7.2f}\")\n",
    "print(f\"answer 50/100분위:  {percentile50:7.2f}\")\n",
    "print(f\"answer 75/100분위:  {percentile75:7.2f}\")\n",
    "print(f\"answer IQR:        {percentileIQR:7.2f}\")\n",
    "print(f\"answer MAX/100분위: {percentileMAX:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "generous-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 6))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 표현\n",
    "# 참고: https://leebaro.tistory.com/entry/%EB%B0%95%EC%8A%A4-%ED%94%8C%EB%A1%AFbox-plot-%EC%84%A4%EB%AA%85\n",
    "plt.boxplot(train_answer_starts, labels=['token counts'], showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-prompt",
   "metadata": {},
   "source": [
    "### load data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-superior",
   "metadata": {},
   "source": [
    "CLS 토큰, 질문, SEP토큰, 지문, SEP토큰을 추가한 총 길이가 384 이하, 질문 길이가 64 이하로 잘라 하나로 합친 훈련 데이터를 만듭니다\n",
    "CLS 토큰부터 첫번쨰 SEP 토큰까지는 0으로, 지문과 두번째 SEP 토큰은 1로 segmentation encoding 한 뒤, 답변의 위치 역시  질문의 길이와 앞에 추가한 특수토큰 CLS와 SEP을 고려해 수정해 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "suitable-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = os.path.join(data_dir, \"korquad_train.json\")\n",
    "dev_json = os.path.join(data_dir, \"korquad_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "distributed-convention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 384, 'max_query_length': 64}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "\n",
    "args = Config({\n",
    "    'max_seq_length': 384,\n",
    "    'max_query_length': 64,\n",
    "})\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "european-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 데이터셋 파일을 메모리에 로딩하는 함수\n",
    "def load_data(args, filename):\n",
    "    inputs, segments, labels_start, labels_end = [], [], [], []\n",
    "\n",
    "    n_discard = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, desc=f\"Loading ...\")):\n",
    "            data = json.loads(line)\n",
    "            token_start = data.get(\"token_start\")\n",
    "            token_end = data.get(\"token_end\")\n",
    "            question = data[\"question\"][:args.max_query_length]\n",
    "            context = data[\"context\"]\n",
    "            answer_tokens = \" \".join(context[token_start:token_end + 1])\n",
    "            context_len = args.max_seq_length - len(question) - 3\n",
    "\n",
    "            if token_end >= context_len:\n",
    "                # 최대 길이내에 token이 들어가지 않은 경우 처리하지 않음\n",
    "                n_discard += 1\n",
    "                continue\n",
    "            context = context[:context_len]\n",
    "            assert len(question) + len(context) <= args.max_seq_length - 3\n",
    "\n",
    "            tokens = ['[CLS]'] + question + ['[SEP]'] + context + ['[SEP]']\n",
    "            ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "            ids += [0] * (args.max_seq_length - len(ids))\n",
    "            inputs.append(ids)  # padding = 'post'\n",
    "            segs = [0] * (len(question) + 2) + [1] * (len(context) + 1)\n",
    "            segs += [0] * (args.max_seq_length - len(segs))\n",
    "            segments.append(segs)\n",
    "            token_start += (len(question) + 2)\n",
    "            labels_start.append(token_start)\n",
    "            token_end += (len(question) + 2)\n",
    "            labels_end.append(token_end)\n",
    "    print(f'n_discard: {n_discard}')\n",
    "\n",
    "    return (np.array(inputs), np.array(segments)), (np.array(labels_start), np.array(labels_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "undefined-platform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affe09c604b347c8b1825686027576b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_discard: 430\n",
      "train_inputs: (59977, 384)\n",
      "train_inputs: (59977, 384)\n",
      "train_labels: (59977,)\n",
      "train_labels: (59977,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240953afcdd3408d8f1f312b5cc06fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading ...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_discard: 78\n",
      "dev_inputs: (5696, 384)\n",
      "dev_inputs: (5696, 384)\n",
      "dev_labels: (5696,)\n",
      "dev_labels: (5696,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[    5, 15798,    10, ...,     0,     0,     0],\n",
       "         [    5, 15798,    10, ...,     0,     0,     0],\n",
       "         [    5, 15798,    19, ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    5, 21666,    19, ...,     0,     0,     0],\n",
       "         [    5,   964, 16865, ...,     0,     0,     0],\n",
       "         [    5,   365,    15, ...,     0,     0,     0]]),\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])),\n",
       " (array([ 37, 184,  98, ...,  74, 190,  35]),\n",
       "  array([ 37, 185, 102, ...,  75, 191,  44])))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data load\n",
    "train_inputs, train_labels = load_data(args, train_json)\n",
    "print(f\"train_inputs: {train_inputs[0].shape}\")\n",
    "print(f\"train_inputs: {train_inputs[1].shape}\")\n",
    "print(f\"train_labels: {train_labels[0].shape}\")\n",
    "print(f\"train_labels: {train_labels[1].shape}\")\n",
    "\n",
    "# dev data load\n",
    "dev_inputs, dev_labels = load_data(args, dev_json)\n",
    "print(f\"dev_inputs: {dev_inputs[0].shape}\")\n",
    "print(f\"dev_inputs: {dev_inputs[1].shape}\")\n",
    "print(f\"dev_labels: {dev_labels[0].shape}\")\n",
    "print(f\"dev_labels: {dev_labels[1].shape}\")\n",
    "\n",
    "train_inputs[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "intended-sustainability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    5, 15798,    10, 28935,     9,    11, 29566,    20, 14604,\n",
       "       20424,  3904,    70,    11,  4648,    10,    19,  1910,     4,\n",
       "       22070,    15, 15798,    10, 28935,     9,    11, 29566,    16,\n",
       "         626, 14604,    38, 14028, 11773, 13829,   384,  8376,  3021,\n",
       "        1239,  6874,    16,  1687,  5958,  2694,  5061,     7,    30,\n",
       "        1613, 15798,    10, 28065,    75,  4415,  1816,  4978,    27,\n",
       "         347,   145,   107,  2703,   263,    11,     1,    18,  5853,\n",
       "          99,  9677,    24, 11969,    13,  7595,   437,  1019,  5907,\n",
       "         257,  3794,  1972,    20, 11278,    11, 29566,     9,   612,\n",
       "       12631, 13214,  1732,    76,     7,   110,  8802, 17581,   354,\n",
       "        9648,  2060,    21,  1682, 22110, 18164,    17, 21076, 14980,\n",
       "           9,  6874,    81, 11325,  4239,  3597,  1010,  1035, 17670,\n",
       "           8,  2447,  1306,    35,   443,    11, 29566,     9,   315,\n",
       "       12729, 14457,    30,  7938,  3742, 10766,   634,  9971, 17590,\n",
       "       19424,    10,   285,  4080,    61, 17573,   483,     7,  7588,\n",
       "           9,   473,   338,   147,  1924,     9, 11016,   136,  1034,\n",
       "          13, 11672,    40,  3436,  5217,  7898, 11684,    57,   830,\n",
       "           9,    19,  3319,    86,   220,   464, 14980,     9, 20515,\n",
       "         412,   991,   684,  1924,     9,   634,   920,   144,   430,\n",
       "          34,    25,     7,  4210,  6874,  2150,    16, 22070,   298,\n",
       "        1159,    75,  1098,  8802,  7490,   805,    35, 18678,    16,\n",
       "        1657,  1970,  2272,    53,     7,   110,  6559,  2178,    24,\n",
       "         756,    82,    30,   315,   684,  3772, 18678,    12,    16,\n",
       "        1682, 22110,     9, 22469,    22,  1757,    61,  8817,   194,\n",
       "         164,  1693,   749,     8,  6739, 12202,    10,   494,     7,\n",
       "         502, 12181,    18,    46,    15,   374,    17,  1680,   708,\n",
       "       26344,    22,  1757,   432,   465,   351,    32, 18563,   710,\n",
       "           8,  2585,  1384, 16071,   265,  3360,     7,    38,   747,\n",
       "          82,   383,   678,   200,    26,   590,  1281,    41,  1172,\n",
       "          31,    16,  2178,    43,  3044,   156,    17,   647,   468,\n",
       "        7490,    41,    84,   758,    92,    33,  3401,   369, 18319,\n",
       "           8,  2582, 29798,  1102,    17,    30,  4573, 11170,   139,\n",
       "          58,   220,   773,    19,   211, 23824,    25,     7,     4,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question과 Context가 포함된 입력데이터 1번째\n",
    "train_inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "explicit-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer위치의 시작점과 끝점 라벨 1번째\n",
    "train_labels[0][0]  # 시작 인덱스의 array중 첫번째\n",
    "train_labels[1][0]  # 끝 인덱스의 array중 첫번째"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-notice",
   "metadata": {},
   "source": [
    "# Modeling BERT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-harvest",
   "metadata": {},
   "source": [
    "transformer에서도 사용했던 utility function들을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "essential-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸리티 함수들\n",
    "\n",
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
    "\n",
    "\n",
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer\n",
    "\n",
    "\n",
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "proud-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode == \"embedding\" 일 경우 Token Embedding Layer 로 사용되는 layer 클래스입니다. \n",
    "\n",
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighted Shared Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "annual-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Positional Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: positional embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "spoken-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "particular-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "heard-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "communist-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "turkish-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, enc_tokens, segments):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_tokens: encoder tokens\n",
    "        :param segments: token segments\n",
    "        :return logits_cls: CLS 결과 logits\n",
    "        :return logits_lm: LM 결과 logits\n",
    "        \"\"\"\n",
    "        enc_self_mask = get_pad_mask(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = enc_out\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-desperate",
   "metadata": {},
   "source": [
    "# Compile BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "confused-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4KorQuAD(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(name='BERT4KorQuAD')\n",
    "\n",
    "        self.bert = BERT(config)\n",
    "        self.dense = tf.keras.layers.Dense(2)\n",
    "    \n",
    "    def call(self, enc_tokens, segments):\n",
    "        logits_cls, logits_lm = self.bert(enc_tokens, segments)\n",
    "\n",
    "        hidden = self.dense(logits_lm) # (bs, n_seq, 2)\n",
    "        start_logits, end_logits = tf.split(hidden, 2, axis=-1)  # (bs, n_seq, 1), (bs, n_seq, 1)\n",
    "\n",
    "        start_logits = tf.squeeze(start_logits, axis=-1)\n",
    "        start_outputs = tf.keras.layers.Softmax(name=\"start\")(start_logits)\n",
    "\n",
    "        end_logits = tf.squeeze(end_logits, axis=-1)\n",
    "        end_outputs = tf.keras.layers.Softmax(name=\"end\")(end_logits)\n",
    "\n",
    "        return start_outputs, end_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "utility-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 8,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 6,\n",
       " 'n_seq': 384,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 8, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 6, \"n_seq\": 384, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "flexible-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_batch_size = 32 \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).shuffle(10000).batch(bert_batch_size)\n",
    "dev_dataset = tf.data.Dataset.from_tensor_slices((dev_inputs, dev_labels)).batch(bert_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "thousand-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT4KorQuAD(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "after-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset, loss_fn, acc_fn, optimizer):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    p_bar = tqdm(dataset)\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(p_bar):\n",
    "        with tf.GradientTape() as tape:\n",
    "            start_outputs, end_outputs = model(enc_tokens, segments)\n",
    "\n",
    "            start_loss = loss_fn(start_labels, start_outputs)\n",
    "            end_loss = loss_fn(end_labels, end_outputs)\n",
    "            loss = start_loss + end_loss\n",
    "\n",
    "            start_acc = acc_fn(start_labels, start_outputs)\n",
    "            end_acc = acc_fn(end_labels, end_outputs)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "        if batch % 10 == 9:\n",
    "            p_bar.set_description(f'loss: {metric_start_loss.result():0.4f}, {metric_end_loss.result():0.4f}, acc: {metric_start_acc.result():0.4f}, {metric_end_acc.result():0.4f}')\n",
    "    p_bar.close()\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "according-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataset, loss_fn, acc_fn):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(dataset):\n",
    "        start_outputs, end_outputs = model(enc_tokens, segments)\n",
    "\n",
    "        start_loss = loss_fn(start_labels, start_outputs)\n",
    "        end_loss = loss_fn(end_labels, end_outputs)\n",
    "\n",
    "        start_acc = acc_fn(start_labels, start_outputs)\n",
    "        end_acc = acc_fn(end_labels, end_outputs)\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "collective-million",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc07112083f14e4a82e746af2cfb14f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0 >> loss: 3.6700, 4.2159, acc: 0.1289, 0.1103\n",
      "save best model\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(1):\n",
    "    train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model, dev_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-interface",
   "metadata": {},
   "source": [
    "# Use Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-template",
   "metadata": {},
   "source": [
    "learning rate = 5e-5를 사용하고, 1024의 클래스 분포는 너무 작기 때문에 마지막 단의 softmax를 풀고 output_dim = 8192로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-technician",
   "metadata": {},
   "source": [
    "모델의 구조를 바꾼다면 저장한 weight와 맞지 않으므로 여기선 수정할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "corrected-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4KorQuAD(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(name='BERT4KorQuAD')\n",
    "\n",
    "        self.bert = BERT(config)\n",
    "        self.dense = tf.keras.layers.Dense(2)\n",
    "    \n",
    "    def call(self, enc_tokens, segments):\n",
    "        logits_cls, logits_lm = self.bert(enc_tokens, segments)\n",
    "\n",
    "        hidden = self.dense(logits_lm) # (bs, n_seq, 2)\n",
    "        start_logits, end_logits = tf.split(hidden, 2, axis=-1)  # (bs, n_seq, 1), (bs, n_seq, 1)\n",
    "\n",
    "        start_logits = tf.squeeze(start_logits, axis=-1)\n",
    "        start_outputs = tf.keras.activations.linear(start_logits)\n",
    "\n",
    "        end_logits = tf.squeeze(end_logits, axis=-1)\n",
    "        end_outputs = tf.keras.activations.linear(end_logits)\n",
    "\n",
    "        return start_outputs, end_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "chicken-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 512,\n",
       " 'n_head': 8,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 6,\n",
       " 'n_seq': 384,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 512, \"n_head\": 8, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 6, \"n_seq\": 384, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "domestic-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT4KorQuAD\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (BERT)                  multiple                  29202944  \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  1026      \n",
      "=================================================================\n",
      "Total params: 29,203,970\n",
      "Trainable params: 29,203,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = os.path.join(model_dir, 'bert_pretrain_32000.hdf5')\n",
    "\n",
    "model = BERT4KorQuAD(config)\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    #  pretrained model 을 로드하기 위해 먼저 모델이 생성되어 있어야 한다.\n",
    "    enc_tokens = np.random.randint(0, len(vocab), (4, 10))\n",
    "    segments = np.random.randint(0, 2, (4, 10))\n",
    "    model(enc_tokens, segments)\n",
    "    model.summary()\n",
    "    # checkpoint 파일로부터 필요한 layer를 불러온다. \n",
    "    model.load_weights(os.path.join(model_dir, \"bert_pretrain_32000.hdf5\"), by_name=True)\n",
    "else:\n",
    "    print('NO Pretrained Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "medical-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = tf.keras.layers.Input(shape=(384))\n",
    "inputs_2 = tf.keras.layers.Input(shape=(384))\n",
    "base_output = model(inputs_1, inputs_2)\n",
    "\n",
    "start_output, end_output = base_output\n",
    "start_output, end_output = tf.keras.layers.Flatten()(start_output), tf.keras.layers.Flatten()(end_output)\n",
    "start_output, end_output = tf.keras.layers.Dense(384, activation='sigmoid')(start_output), \\\n",
    "                            tf.keras.layers.Dense(384, activation='sigmoid')(end_output)\n",
    "output = start_output, end_output\n",
    "\n",
    "model_mod = tf.keras.models.Model(inputs=(inputs_1, inputs_2), outputs=output)\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "elementary-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT4KorQuAD\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (BERT)                  multiple                  29202944  \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  1026      \n",
      "=================================================================\n",
      "Total params: 29,203,970\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 29,202,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "attended-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BERT4KorQuAD (BERT4KorQuAD)     ((None, 384), (None, 29203970    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 384)          0           BERT4KorQuAD[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 384)          0           BERT4KorQuAD[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 384)          147840      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 384)          147840      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,499,650\n",
      "Trainable params: 296,706\n",
      "Non-trainable params: 29,202,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "nonprofit-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mod.load_weights(os.path.join(data_dir, \"korquad_bert_pretrain.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "distinct-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset, loss_fn, acc_fn, optimizer):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    p_bar = tqdm(dataset)\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(p_bar):\n",
    "        with tf.GradientTape() as tape:\n",
    "            start_outputs, end_outputs = model((enc_tokens, segments))\n",
    "\n",
    "            start_loss = loss_fn(start_labels, start_outputs)\n",
    "            end_loss = loss_fn(end_labels, end_outputs)\n",
    "            loss = start_loss + end_loss\n",
    "            start_acc = acc_fn(start_labels, start_outputs)\n",
    "            end_acc = acc_fn(end_labels, end_outputs)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "        if batch % 10 == 9:\n",
    "            p_bar.set_description(f'loss: {metric_start_loss.result():0.4f}, {metric_end_loss.result():0.4f}, acc: {metric_start_acc.result():0.4f}, {metric_end_acc.result():0.4f}')\n",
    "    p_bar.close()\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "reported-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataset, loss_fn, acc_fn):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(dataset):\n",
    "        start_outputs, end_outputs = model((enc_tokens, segments))\n",
    "\n",
    "        start_loss = loss_fn(start_labels, start_outputs)\n",
    "        end_loss = loss_fn(end_labels, end_outputs)\n",
    "\n",
    "        start_acc = acc_fn(start_labels, start_outputs)\n",
    "        end_acc = acc_fn(end_labels, end_outputs)\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "pacific-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "unlikely-fantasy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx5klEQVR4nO3deZhcZZ3//fe39+70kqTT2RMSSAI0yNpEcHBFJYxLcAxjoo74E2VG4XFh5nHg54zj8JPfM4gjjooLCspwgQFRx4hoRBABhZCwk0CgSQJJyL50Z+vqru7v88c5lVSKqq7q6jpd3V2f13XVVafuc5/73HW6+3z7Xs455u6IiIgUWlmxKyAiIqOTAoyIiERCAUZERCKhACMiIpFQgBERkUhUFLsCxTRhwgSfNWtWsashIjKiPP744zvdvSVbvpIOMLNmzWLVqlXFroaIyIhiZq/kkk9dZCIiEgkFGBERiYQCjIiIREIBRkREIqEAIyIikYg0wJjZAjNba2btZnZlmvXVZnZHuH6Fmc1KWndVmL7WzM5PSr/ZzLab2XMZ9vmPZuZmNiGSLyUiIjmJLMCYWTlwA3AB0AosMbPWlGyXAHvcfQ5wPXBtuG0rsBg4CVgAfDcsD+AnYVq6fc4A3g28WtAvIyIiAxZlC2Y+0O7u69y9G1gKLEzJsxC4JVy+CzjPzCxMX+ruMXdfD7SH5eHuDwK7M+zzeuCLQFGeQbCts4vfr95ajF2LiAw7UQaYacDGpM+bwrS0edw9DnQAzTluexQzWwhsdvens+S71MxWmdmqHTt25PI9cvbRH63g0lsfJxbvLWi5IiIj0agY5DezOuB/A1/Oltfdb3T3Nndva2nJeqeDAdm05xAAnYfiBS1XRGQkijLAbAZmJH2eHqalzWNmFUATsCvHbZMdB8wGnjazDWH+J8xs8iDqP2C1VcEwUcehnqHcrYjIsBRlgFkJzDWz2WZWRTBovywlzzLg4nB5EXC/B89wXgYsDmeZzQbmAo9l2pG7P+vuE919lrvPIuhSO8Pdh3RApLYyEWC6h3K3IiLDUmQBJhxTuRxYDjwP3Onuq83sajN7f5jtJqDZzNqBK4Arw21XA3cCa4DfAZe5ey+Amf0UeAQ43sw2mdklUX2HgUq0YPYeVAtGRCTSuym7+z3APSlpX05a7gIuyrDtNcA1adKX5LDfWQOtayEkWjAKMCIio2SQf7g4HGA0BiMiogBTSFUVweHsOKgxGBERBZgC6u7tA9SCEREBBZiCisXDAKMxGBERBZhCivUEV/CrBSMiogBTUIkuMo3BiIgowBRUrEdjMCIiCQowBaQxGBGRIxRgCihxF+XOrh56+4ryxAARkWFDAaaAYvE+qivKcIdOdZOJSIlTgCkQd6c73seUphoAdmugX0RKnAJMgSTGX6aOrQVg575YMasjIlJ0CjAFkhpgdh1QC0ZESpsCTIEkBvinJVow+9WCEZHSpgBTIN1hC2ZyUw1msHO/WjAiUtoUYAok0UVWV1XO+LoqtWBEpOQpwBRI4ir+6opymuur2KUAIyIlTgGmQBJjMNWVZUyor2aXushEpMQpwBRIoousuryM5vpqdZGJSMmLNMCY2QIzW2tm7WZ2ZZr11WZ2R7h+hZnNSlp3VZi+1szOT0q/2cy2m9lzKWVdZ2YvmNkzZvZLMxsb5XdLdTjAVJYxob5KLRgRKXmRBRgzKwduAC4AWoElZtaaku0SYI+7zwGuB64Nt20FFgMnAQuA74blAfwkTEt1L3Cyu58CvAhcVdAvlEXiWTDVFeVMqK9mXyxOV5gmIlKKomzBzAfa3X2du3cDS4GFKXkWAreEy3cB55mZhelL3T3m7uuB9rA83P1BYHfqztz99+4eDz8+Ckwv9Bfqz+EWTEUZzWOqAF1sKSKlLcoAMw3YmPR5U5iWNk8YHDqA5hy37c8ngN+mW2Fml5rZKjNbtWPHjgEU2b/u+JFZZC0N1QDs0O1iRKSEjbpBfjP7EhAHbku33t1vdPc2d29raWkp2H6Tx2AmNQY3vNza0VWw8kVERpooA8xmYEbS5+lhWto8ZlYBNAG7ctz2dczs48B7gY+4+5A+kOXwNOWKssN3VN7acWgoqyAiMqxEGWBWAnPNbLaZVREM2i9LybMMuDhcXgTcHwaGZcDicJbZbGAu8Fh/OzOzBcAXgfe7+8ECfo+cxJK6yMaPqaKqvIwtnWrBiEjpiizAhGMqlwPLgeeBO919tZldbWbvD7PdBDSbWTtwBXBluO1q4E5gDfA74DJ37wUws58CjwDHm9kmM7skLOs7QANwr5k9ZWbfj+q7pZO4kr+qogwzY1JTNdvURSYiJawiysLd/R7gnpS0LyctdwEXZdj2GuCaNOlLMuSfM6jKDlIs3ktFmVFeZgBMaaxliwKMiJSwUTfIXyyJxyUnTGqqYau6yESkhCnAFEgs3kt1Zfnhz1Oaatja0cUQzzUQERk2FGAKJNaT0oJprCEW72PvwZ4i1kpEpHgUYAqku/foAHN4qrK6yUSkRCnAFEjQgjnSRTa5SRdbikhpU4ApkGAM5sjhnNpUC8DmvbrYUkRKkwJMgaTOIpvYUE1VeRkb9wz5NZ8iIsOCAkyBxOJ9VCUFmLIyY/q4WjbuVoARkdKkAFMgsXjvUWMwADPG17Fxt7rIRKQ0KcAUSOo0ZYAZ42t5VS0YESlRCjAFkjoGAzBzfB0dh3roOKRrYUSk9CjAFEh3vO/1XWTj6gA0DiMiJUkBpkBSpylDMAYDsEkzyUSkBCnAFEi6LrJEgNE4jIiUIgWYAoml6SJrqq2ksaZCAUZESpICTAHEe/vo7fPXtWAAZrfUs2GnAoyIlB4FmAJIPC65Kk2AOa5lDO3b9w91lUREik4BpgASASZdC+a4lnq2dnaxPxYf6mqJiBSVAkwBxOK9AEc9cCzhuJZ6ANbtUCtGREpLpAHGzBaY2VozazezK9OsrzazO8L1K8xsVtK6q8L0tWZ2flL6zWa23cyeSylrvJnda2Yvhe/jovxuyWI9mVswcyaOAeBlBRgRKTGRBRgzKwduAC4AWoElZtaaku0SYI+7zwGuB64Nt20FFgMnAQuA74blAfwkTEt1JXCfu88F7gs/D4nu3kSAeX0L5pjmMVSUGS9vPzBU1RERGRaibMHMB9rdfZ27dwNLgYUpeRYCt4TLdwHnmZmF6UvdPebu64H2sDzc/UFgd5r9JZd1C3BhAb9Lv/prwVSWlzGzuU4tGBEpOVEGmGnAxqTPm8K0tHncPQ50AM05bptqkrtvCZe3ApPSZTKzS81slZmt2rFjRy7fI6sjYzDpD+dxLfUKMCJSckblIL+7O+AZ1t3o7m3u3tbS0lKQ/R2ZRfb6LjKAORPrWb/zAN1hPhGRUhBlgNkMzEj6PD1MS5vHzCqAJmBXjtum2mZmU8KypgDb8675ACVaMOmugwE4cUojPb2uVoyIlJQoA8xKYK6ZzTazKoJB+2UpeZYBF4fLi4D7w9bHMmBxOMtsNjAXeCzL/pLLuhj4VQG+Q076G4MBaJ3SAMCa1zqHqkoiIkUXWYAJx1QuB5YDzwN3uvtqM7vazN4fZrsJaDazduAKwplf7r4auBNYA/wOuMzdewHM7KfAI8DxZrbJzC4Jy/oP4F1m9hLwzvDzkOjvQkuA2RPqqaksY80WBRgRKR0VURbu7vcA96SkfTlpuQu4KMO21wDXpElfkiH/LuC8wdQ3X/1daAlQXmYcP6mB5xVgRKSEjMpB/qHWnaUFA9A6tZE1WzoJegBFREY/BZgCyNZFBsFA/96DPWzp6BqqaomIFJUCTAFkm6YM0DqlEdBAv4iUDgWYAoj19GIGleWWMU/r1EbKDJ7etHfoKiYiUkQKMAWQeFxycJeb9OqqKjhhciNPvrp36ComIlJEWQOMmc0zs/sSdy82s1PM7F+ir9rIEYv3UVWePVafPnMsT2/cS1+fBvpFZPTLpQXzQ+AqoAfA3Z8huGhSQrF4b8YpyslOnzmOfbG4rugXkZKQS4Cpc/fUq+j1eMYksZ6+fmeQJZw+cyyAuslEpCTkEmB2mtlxhDePNLNFwJb+NyktiTGYbGY3j6GxpoInN+4ZglqJiBRXLlfyXwbcCJxgZpuB9cBHIq3VCBMEmOxdZGVlxmkzx/H4KwowIjL65dKCcXd/J9ACnODu5+a4XckIxmByOyRvnD2eF7ftZ9f+WMS1EhEprlzOij8HcPcD7r4vTLsruiqNPLl2kQGcc1wzAI+uS/dQThGR0SNjF5mZnQCcBDSZ2d8krWoEaqKu2EgSi/cxtrYyp7xvmNbEmKpyHlm3k/ecMiXimomIFE9/YzDHA+8FxgLvS0rfB3wqwjqNOLGeXqoaqnPKW1lexvzZ4/nLy7sirpWISHFlDDDu/ivgV2Z2jrs/MoR1GnG6B9BFBkE32R/X7mBbZxeTGtUYFJHRKZdZZE+a2WUE3WWHz4bu/onIajXC5DqLLOGcYycA8MjLu7jw9GlRVUtEpKhy+bf7VmAycD7wJ2A6QTeZhAYyiwyCG182j6nigbXbI6yViEhx5XJWnOPu/woccPdbgPcAb4y2WiPLQGaRQfCEy7ce38IDL+6gV/clE5FRKpezYk/4vtfMTgaagInRVWnkGWgXGcB5J0xi78EennxVF12KyOiUS4C50czGAf8CLAPWANdGWqsRxN0HPMgP8OZ5E6goM+57Qd1kIjI6ZT0ruvuP3H2Puz/o7se6+0Tgt7kUbmYLzGytmbWb2ZVp1leb2R3h+hVmNitp3VVh+lozOz9bmWZ2npk9YWZPmdnDZjYnlzoO1uGnWQ5gDAagsaaSs2aN5/7nFWBEZHTq96xoZueY2SIzmxh+PsXMbgf+nK1gMysHbgAuAFqBJWbWmpLtEmCPu88BridsGYX5FhPMXFsAfNfMyrOU+T3gI+5+GnA7QYsrcrk8LjmT806cyNpt+3h118FCV0tEpOgyBhgzuw64Gfgg8Bsz+yrwe2AFMDeHsucD7e6+zt27gaXAwpQ8C4FbwuW7gPMseCzkQmCpu8fcfT3QHpbXX5lOcJcBCMaJXsuhjoMWi/cCUDXALjKABSdPBuDuZ4ekqiIiQ6q/62DeA5zu7l3hGMxG4GR335Bj2dPCbRI28frZZ4fzuHvczDqA5jD90ZRtExeMZCrzk8A9ZnYI6ATOTlcpM7sUuBRg5syZOX6VzGI9iRbMwAPM9HF1nD5zLHc/vYXPvG1IevRERIZMf2fFLnfvAnD3PcBLAwguxfAF4K/dfTrwY+Ab6TK5+43u3ububS0tLYPe6ZEusvxuMP3eU6ayZkunnnIpIqNOf2fFY81sWeIFzE75nM1mYEbS5+lhWto8ZlZB0LW1q59t06abWQtwqruvCNPvAN6UQx0HLdFFls8YDMB73jAFM7j7aT3DTURGl/66yFLHS/5zgGWvBOaa2WyCwLAY+HBKnmXAxcAjwCLgfnf3MIDdbmbfAKYSjPk8BliGMvcQ3PV5nru/CLwLeH6A9c1Ld56zyBImN9Vw1qzxLHt6M589bw7BEJSIyMjX380u/zSYgsMxlcuB5UA5cLO7rzazq4FV7r4MuAm41czagd0EAYMw350E19zEgcvcvRcgXZlh+qeAn5tZH0HAGZJ7pQ22iwzgg2dM459//ixPvLqXM48ZV6iqiYgUVS43u8ybu98D3JOS9uWk5S7gogzbXgNck0uZYfovgV8OssoDNphpygnvPWUqV/96DXesfFUBRkRGDT36eJBiPYkxmPwP5ZjqCt536lR+/fQW9nX1ZN9ARGQEUIAZpEJ0kQF86KwZHOrp5e5nNNgvIqND1i4yM/s1wUWMyTqAVcAPElOZS1UhusgATpsxlhMmN3DrI6+w+KwZGuwXkREvl3+71wH7gR+Gr06C58HMCz+XtMPTlPOcRZZgZnz8TbNYs6WTR9ftLkTVRESKKpez4pvc/cPu/uvw9VHgLHe/DDgj4voNe4O5kj/VhadPY/yYKm56eP2gyxIRKbZczor1Znb4nirhcn34sTuSWo0g3b2F6SIDqKks56NnH8N9L2xjna7sF5ERLpcA84/Aw2b2RzN7AHgI+CczG8ORG1WWrEQLJp+bXabzd2cfQ2VZGT9SK0ZERrisg/zufo+ZzQVOCJPWJg3sfzOqio0UsXgvleVGeVlhBuVbGqq5qG06d67ayGfedhzTx9UVpFwRkaGW67/dZxI8m+VU4G/N7GPRVWlkyedxydlc9vY5GMYNf3y5oOWKiAylrAHGzG4Fvg6cC5wVvtoirteIEYv3FmSAP9nUsbV86KwZ/GzVRjbu1sPIRGRkyuVWMW1Aq7unXgsjBGMwhRp/SfaZtx/HHSs38q37XuK6i04tePkiIlHL5cz4HDA56oqMVEEXWeEDzJSmWv7unGO464lNrH6to+Dli4hELZcz4wRgjZktH+DzYEpC0EVW2DGYhM++Yy5jayu5+tdrUANSREaaXLrIvhJ1JUayWLxv0FfxZ9JUV8kV75rHv/5qNctXb2PByWpIisjIkcs05UE9F2a0646oiyxhyfyZ/Pcjr3DNPWt467wWaquiaS2JiBRaxjOjmT0cvu8zs86k1z4z6xy6Kg5vUUxTTlZRXsb/ufBkNu4+xPV/eDGy/YiIFFrGAOPu54bvDe7emPRqcPfGoavi8BbFNOVUZx/bzJL5M/nRQ+t4ZtPeSPclIlIoOZ0ZzazczKaa2czEK+qKjRSxnujGYJJdecEJTKiv5ot3PUN3+IgAEZHhLJcLLf8fYBtwL/Cb8HV3xPUaMWLxPqrKow8wTbWVfPXCk3lh6z6+ca+6ykRk+MvlzPg54Hh3P8nd3xC+TsmlcDNbYGZrzazdzK5Ms77azO4I168ws1lJ664K09ea2fnZyrTANWb2opk9b2afzaWOgxXlNOVU7z5pMkvmz+AHD77Mn9t3Dsk+RUTylUuA2UjwBMsBMbNy4AbgAqAVWGJmrSnZLgH2uPsc4Hrg2nDbVmAxwf3PFgDfDbvp+ivz48AM4AR3PxFYOtA65yPKacrp/Ot7Wzl2whi+cMdT7D5Q8k9LEJFhLNcnWj4QtiiuSLxy2G4+0O7u69y9m+CEvzAlz0KO3PL/LuA8C54VvBBY6u4xd18PtIfl9Vfmp4Gr3b0PwN2351DHQYv1RDtNOVVdVQXfXnIGew/28LmlT9LbpwswRWR4yuXM+CrB+EsV0JD0ymYaQesnYVOYljaPu8cJWkrN/WzbX5nHAR8ys1Vm9tvwEQOvY2aXhnlW7dixI4ev0b/u3minKafTOrWRqxeexEMv7eRrv3thSPctIpKrfi+0DLuk5rn7R4aoPoNRDXS5e5uZ/Q1wM/Dm1EzufiNwI0BbW9ug/v2P9/bR2+dD2oJJWDx/Jqtf6+QHD67jxCmNXHh6auwWESmufs+M7t4LHGNmVXmUvZlgTCRhepiWNo+ZVQBNwK5+tu2vzE3AL8LlXwI5TUQYjFg4XXgox2CSffl9rcyfPZ5//vkzPP7K7qLUQUQkk1zHYP5sZv86wDGYlcBcM5sdBqjFQOpNMpcBF4fLi4D7w8cCLAMWh7PMZgNzgceylPk/wNvD5bcCkc/lPRxghriLLKGyvIzvfeQMpjTV8ImfrOKlbfuKUg8RkXRyCTAvE1z3UsYAxmDCMZXLgeXA88Cd7r7azK42s/eH2W4Cms2sHbgCuDLcdjVwJ7AG+B1wmbv3ZiozLOs/gA+a2bPA/wd8MofvNiixeC9AUbrIEprrq7n1kjdSVVHGx25+jNf2HipaXUREklkp3wa+ra3NV61alff2G3Ye4G1ff4Bv/O2p/M0Z0wtYs4Fb81onH/rBI7Q0VrP0U2czsbGmqPURkdHLzB5396xPNs7lSv4WM7vOzO4xs/sTr8JUc2QrdhdZstapjdz8v85ia0cXi298lG2dXcWukoiUuFz6dm4DXgBmA/8ObCAYCyl5w6GLLNlZs8bz35+Yz7bOIMhs7VCQEZHiyeXM2OzuNwE97v4nd/8E8I6I6zUiFHsWWTpts8bz35e8kR37Ynzwe3+hffv+YldJREpULmfGnvB9i5m9x8xOB8ZHWKcRo3sYdZElO/OYcfz0U2cTi/ey6Pt/YdUGTWEWkaGXS4D5qpk1Af8I/BPwI+ALkdZqhBhuXWTJ3jC9iV98+q8YV1fFh3+0gt8+u6XYVRKREpP1zOjud7t7h7s/5+5vd/cz3T31epaSFOsZfl1kyWY21/HzT7+Jk6c28unbnuA/f7+WPt27TESGSC6zyOaZ2X1m9lz4+RQz+5foqzb8DadZZJmMH1PF7Z86m79tm86372/nkltW0nGoJ/uGIiKDlMu/3j8EriIci3H3ZwiuoC95iS6yqmHYRZasprKcaz94Cl+98GQebt/J+779ME9t3FvsaonIKJfLmbHO3R9LSYtHUZmR5kgLZngHGAAz46NnH8PSS8+mt89Z9L2/cMMf23W7fxGJTC5nxp1mdhzgAGa2CNCIMUljMCMgwCScecx47vncm1lw8mSuW76WD//wUTbtOVjsaonIKJTLmfEy4AfACWa2Gfg88A9RVmqkODKLbPiOwaTTVFvJt5ecztcvOpXnNnfw7usf5Md/Xq/WjIgUVC6zyNa5+zuBFoLHEZ8LfCDymo0A3fE+zKCy3IpdlQEzMxadOZ3fX/FW5s8ez7//eg2Lvv8XXtQdmUWkQHLu23H3A+6eOPvkcrv+US8WDx6XHDzleWSaNraWH3/8LL75odPYsPMA7/nWQ/zfe55nX5dmmonI4OQ7eDByz6gFFASYkdU9lo6ZceHp0/jDFW/lwtOm8cOH1vH2rz/AnSs36roZEclbvgFGZx2CMZiRNMCfTXN9NddddCq/uuyvOKZ5DF/8+TO8/4aHefDFHZTyYx1EJD8Zz45mts/MOtO89gFTh7COw1asp2/YXsU/GKdMH8td/3AO/7X4NPYc6OFjNz/Gh258lJW6p5mIDEBFphXunvWplaUuFu+jqnz0BRgIus0WnjaNBSdPZuljG/nOH9u56PuP8NZ5LXzhXfM4bcbYYldRRIa50Xl2HCJBF9nIH4PpT3VFORe/aRYP/r9v56oLTuDpTXu58IY/s/jGR3hg7XZ1nYlIRgowgxCLj84usnRqq8r5+7cex8P//A7+5T0nsmHnQT7+45Vc8F8P8T9Pbqant6/YVRSRYSbSs6OZLTCztWbWbmZXpllfbWZ3hOtXmNmspHVXhelrzez8AZT5LTMbkqdsJaYpl5L66go++eZjefCLb+frF51Kb5/z+Tue4txr7+ebf3iR7XpUs4iEIjs7mlk5cANwAdAKLDGz1pRslwB73H0OcD1wbbhtK8ENNU8CFgDfNbPybGWaWRswLqrvlGq0TFPOR1VFGYvOnM7yz7+Fmz/exgmTG/nmH17iTf9xP5fd/gSPrtul7jOREpdxkL8A5gPt7r4OwMyWAguBNUl5FgJfCZfvAr5jwVWLC4Gl7h4D1ptZe1gemcoMg891wIcZojsNxHp6qW6oHopdDVtlZcY7TpjEO06YxIadB7htxSvcuWoTv3lmC7MnjGHRmdP5wOnTmDq2tthVFZEhFmX/zjRgY9LnTWFa2jzuHgc6gOZ+tu2vzMuBZe7e7404zexSM1tlZqt27NgxoC+UqjveR3VlabZg0pk1YQxfek8rj151HtctOoWJDdVct3wtf3Xt/Xz0Ryv4nyc3c6i7t9jVFJEhEmULZsiY2VTgIuBt2fK6+43AjQBtbW2D6sMpxTGYXNRWlXNR2wwuapvBq7sO8vMnNvHzJzbx+TueoraynPNOnMh7T5nC246fSI0CtMioFWWA2QzMSPo8PUxLl2eTmVUATcCuLNumSz8dmAO0h/cFqzOz9nBsJzKxeO+wf9hYsc1sruML75rH586by4r1u7n7mdf47XNbufuZLYypKuedrZN4zxum8JZ5LQo2IqNMlAFmJTDXzGYTBIHFBOMjyZYBFwOPAIuA+93dzWwZcLuZfYPgrgFzgccI7oH2ujLdfTUwOVGome2POrhAeCW/AkxOysqMc45r5pzjmvn395/Eo+t285tng2Dzq6deo7aynHPnTuBdJ07i7SdMpKXEx7ZERoPIAoy7x83scmA5UA7c7O6rzexqYJW7LwNuAm4NB/F3Ez6KOcx3J8GEgDhwmbv3AqQrM6rvkE0pzyIbjIryMs6dO4Fz507g6oUn88jLu/jD89v4w5pt3LtmG2Zw2oyxvPPESbzt+BZOnNxIWZnuryoy0lgpTyVta2vzVatW5bVtX59z7P++h8+dN5cvvGtegWtWmtydNVs6ue/57fzh+W08s6kDgAn1VfzVnAmcO2cCb57bwuSmmiLXVKS0mdnj7t6WLd+oGOQvhu7wyvVSuZJ/KJgZJ01t4qSpTXz2vLls6+zioZd28vBLO3i4fSe/euo1AOZOrA9aQHMm0HbMeJrqKotccxFJRwEmT7F4GGDURRaZSY01LDpzOovOnE5fn/PC1n083L6Dh17aye0rXuXHf96AGRw/qYE3zh7PWbPHM3/WeCY2qoUjMhwowOQpFg+u59Ag/9AoKzNapzbSOrWRS99yHF09vTz56l5WbtjNY+t387PHN3HLI68AMKu5jrNmBQHn9BljOa6lXmM4IkWgAJOnWE+iBaMAUww1leWHZ6UB9PT2sfq1Tlau382K9bu59/lt/OzxTQA0VFdwyowmTp0+ltNmjOW0mWOZ2KBWjkjUFGDylOgi03Uww0NleVkQPGaM5VNvOZa+PuflHft5auNentq4l6c37eXGB9cRDx8BPbWphtNmjg3HfBo5aWqTpkaLFJgCTJ6OdJFpDGY4Kisz5k5qYO6kBi5qC67N7erp5bnNHUcFnXue3Xp4m5aG6jDYBAGndUojM8fXqXtNJE8KMHk6PMivWWQjRk1lOW2zxtM2a/zhtI5DPax5rZPVr3WwZksna17r5KGXdtIbtnTqqyuYN6meeWGwOn5SA/Mm1dPSUE141wgRyUABJk8agxkdmmorjxrLgaCl89K2/YeDztqt+1i+eitLV248art5k+qZO6mBeRPrmTe5gXmTGphQr242kQQFmDwdvg5GXWSjTk1lOW+Y3sQbpjcdTnN3du7v5qVt+3hx2z5e3L6fl7bt4zfPbOH2Qz2H8zXVVjJ7whiOnTCG2RPGMLtlDLOag+Ux1fpzk9Ki3/g8xXo0TbmUmBktDdW0NFTzpjkTDqe7Ozv2xVi7bR8vbtvP+p37Wb/zAI+u28Uvnjz63q6TGquDoDOhntkT6pg9oZ5ZzXVMH1dHbZX+UZHRRwEmT4kxmBqNwZQ0M2NiYw0TG2t489yWo9Yd6u5lw64DbNh5gHU7D7A+fC1fvZXdB7qPytvSUM2McbXMGF/HjHF1zBhfG77XMaWphopy/Z7JyKMAkyddyS/Z1FaVc+KURk6c0vi6dR0He1i3cz+v7j7Ixt0H2bj7EBv3HOTxV/Zw9zNbDk8yACgvM6aOrQkCThh8pjTVMmVsDVObapncVKNHHciwpACTJ13JL4PRVFfJ6TPHcfrMca9bF+/tY0tHVxB49hwJPq/uPsh9L2xn5/7Y67YZP6aKKU01TGmqZerYGiY3BcFnSlMNU8fWMqmxRtdsyZBTgMlTYhaZ/mil0CrKy4KusvF1add39fSypaOLLXsPBe8dh3gt/Lxpz0FWbthNR9LEAwAzmFBfHQahIBBNbKympb466OJrqGZiQzXj6qp03Y8UjAJMntRFJsVSU1keThYYkzHPgVj8cPAJgtGRQLR+5wH+8vIu9nXFX7ddRZkxob46KfhU09IQBKCWMAhNbKyhpb5a/1xJVgoweUp0kemPTIajMdUVzJlYz5yJ9RnzHOruZce+GNv3dbF9X+zIcmeM7ftibOno4ulNHew6ECPdY6PG1lUysaGaCfXVjB9TRfOYKprD5Qn1VYwfc2S5saZSLaMSpACTp1i8j8pyo1x/NDJC1VaVM7O5jpnN6bviEuK9few60P26AJT4vGt/N6tf62TX/hidaVpFEExUSASh8WEgOrJ8dHAaW1tJU22lZs6NAgoweerW45KlRFSUlzGpsYZJjTVAU795u+N97DnYza793ew6EGP3gW527u9m91HL3Ty7aS+7DnSn7aZLaKipYGxdJWNrq4L3uiD4jKurpCmxPKaSpsR6BaZhRwEmT7F4r2aQiaSoqkgORtnF4r3sOdDDrgMxdoXBZ+/BbvYe6mHvwZ6jljftOcSeg910HOpJ22WXkAhM4+qqaKpNH5jG1lXSUFNJY21F8F5TwZiqCnXjFVikAcbMFgD/BZQDP3L3/0hZXw38N3AmsAv4kLtvCNddBVwC9AKfdffl/ZVpZrcBbUAP8Bjw9+5+9FSaAor19CnAiAxSdUU5k5vKmdyU+/N5+vqcfV1x9hwOPkHQ2XNgcIHJLHh2UBB4KmmoqaAxDD7Jnxv6+axejaNFFmDMrBy4AXgXsAlYaWbL3H1NUrZLgD3uPsfMFgPXAh8ys1ZgMXASMBX4g5nNC7fJVOZtwEfDPLcDnwS+F9X3i8X7qNbFbSJDrqzMaKqrpKmuckDbJQLT3kPd7D3Yw76uOJ1dPezr6qHzUDx4D9M6DwXvm/ce4vlDQZ59sXi/AQqC6+JSW0b11RWMqQ7ejyyXvy5tTHUFDTXBe11l+ahoTUXZgpkPtLv7OgAzWwosBJIDzELgK+HyXcB3LLgH+kJgqbvHgPVm1h6WR6Yy3f2eRKFm9hgwPaovBkHTvkp9vSIjRnJgOqY5e/5UfX3Oge44nV3xlKAUBqtDPUet6wwD1paOLg7E4uyPxTkQi9OXJUhB0JqqqyynvuZIcBpTVUH94YAVBKiGpOB0dAAL81RVUFddTlV5WVEeLxFlgJkGbEz6vAl4Y6Y87h43sw6gOUx/NGXbaeFyv2WaWSXwd8DnBln/fgUtGAUYkVJRVmY01ARjN1CbVxnuzqGe3jDY9HIgFmdfVxB4DnQHQWh/+Hl/uH5/UnDauPvg4eUDsd7Dd3XPpqLMqKsKglLi/d/e18qZx4zPvvEgjMZB/u8CD7r7Q+lWmtmlwKUAM2fOzHsnGoMRkYEyM+qqKqirqoCGwZcXi/ceDlSJwLMvfD8Y6+VAd5yD3cH6o96740MyXhRlgNkMzEj6PD1MS5dnk5lVEMyB3JVl24xlmtm/AS3A32eqlLvfCNwI0NbWlkNjNb1YvDf4JRERKZLqinKqK8oZP6aq2FVJK8p/wVcCc81stplVEQzaL0vJswy4OFxeBNzv7h6mLzazajObDcwlmBmWsUwz+yRwPrDE3XNrNw5Cd69aMCIi/YnsX/BwTOVyYDnBlOKb3X21mV0NrHL3ZcBNwK3hIP5ugoBBmO9OggkBceAyd+8FSFdmuMvvA68Aj4SDWb9w96uj+n6xHo3BiIj0J9I+nnBm1z0paV9OWu4CLsqw7TXANbmUGaYPaX9VTFfyi4j0S/+C50lX8ouI9E9nyDwFLRgdPhGRTHSGzFOsp0+36hcR6YfOkHlw97CLTGMwIiKZKMDkId7n9DnqIhMR6YfOkHk4/LhkTVMWEclIZ8g8dCcCjLrIREQyUoDJQyzeC6iLTESkPzpD5iHWoy4yEZFsdIbMQ0xdZCIiWSnA5CHRRaYHjomIZKYzZB40i0xEJDudIfNweAxGXWQiIhkpwORBs8hERLLTGTIP3eoiExHJSmfIPGgWmYhIdgoweVAXmYhIdjpD5uFIC0aHT0QkE50h83DkSn51kYmIZKIAkwddaCkikl2kZ0gzW2Bma82s3cyuTLO+2szuCNevMLNZSeuuCtPXmtn52co0s9lhGe1hmVVRfa9YvA8zqCy3qHYhIjLiRRZgzKwcuAG4AGgFlphZa0q2S4A97j4HuB64Nty2FVgMnAQsAL5rZuVZyrwWuD4sa09YdiRi8T6qK8owU4AREckkyhbMfKDd3de5ezewFFiYkmchcEu4fBdwngVn7YXAUnePuft6oD0sL22Z4TbvCMsgLPPCqL5YrEePSxYRyaYiwrKnARuTPm8C3pgpj7vHzawDaA7TH03Zdlq4nK7MZmCvu8fT5D+KmV0KXAowc+bMgX2j0IlTGjnU05vXtiIipaLkRqnd/UZ3b3P3tpaWlrzKWDx/Jl9bdGqBayYiMrpEGWA2AzOSPk8P09LmMbMKoAnY1c+2mdJ3AWPDMjLtS0REhlCUAWYlMDec3VVFMGi/LCXPMuDicHkRcL+7e5i+OJxlNhuYCzyWqcxwmz+GZRCW+asIv5uIiGQR2RhMOKZyObAcKAdudvfVZnY1sMrdlwE3AbeaWTuwmyBgEOa7E1gDxIHL3L0XIF2Z4S7/GVhqZl8FngzLFhGRIrHgn//S1NbW5qtWrSp2NURERhQze9zd27LlK7lBfhERGRoKMCIiEgkFGBERiYQCjIiIRKKkB/nNbAfwSp6bTwB2FrA6haJ6DYzqNTCq18AM13rB4Op2jLtnvVK9pAPMYJjZqlxmUQw11WtgVK+BUb0GZrjWC4ambuoiExGRSCjAiIhIJBRg8ndjsSuQgeo1MKrXwKheAzNc6wVDUDeNwYiISCTUghERkUgowIiISDTcXa8BvoAFwFqCRzlfGUH5MwgeP7AGWA18Lkz/CsFzbp4KX3+dtM1VYX3WAudnqyswG1gRpt8BVOVYtw3As+H+V4Vp44F7gZfC93FhugHfCvfxDHBGUjkXh/lfAi5OSj8zLL893NZyqNPxScfkKaAT+HyxjhdwM7AdeC4pLfJjlGkfWep1HfBCuO9fAmPD9FnAoaRj9/1899/fd+ynXpH/7IDq8HN7uH5WDvW6I6lOG4CnhvJ4kfncUPTfr7R/C4U+OY72F8FjAl4GjgWqgKeB1gLvY0riFwFoAF4EWsM/un9Kk781rEd1+Mf0cljPjHUF7gQWh8vfBz6dY902ABNS0r5G+AcNXAlcGy7/NfDb8Jf8bGBF0i/quvB9XLic+IN4LMxr4bYX5PHz2QocU6zjBbwFOIOjT0yRH6NM+8hSr3cDFeHytUn1mpWcL6WcAe0/03fMUq/If3bAZwgDAcGjQu7IVq+U9f8JfHkojxeZzw1F//1K+90HevIr9RdwDrA86fNVwFUR7/NXwLv6+aM7qg4Ez8s5J1Ndw1+cnRw5sRyVL0tdNvD6ALMWmBIuTwHWhss/AJak5gOWAD9ISv9BmDYFeCEp/ah8Odbv3cCfw+WiHS9STjhDcYwy7aO/eqWs+wBwW3/58tl/pu+Y5XhF/rNLbBsuV4T5rL96JaUbsBGYW4zjlbQucW4YFr9fqS+NwQzcNIJfrIRNYVokzGwWcDpBEx7gcjN7xsxuNrNxWeqUKb0Z2Ovu8ZT0XDjwezN73MwuDdMmufuWcHkrMCnPek0Ll1PTB2Ix8NOkz8U+XglDcYwy7SNXnyD4jzVhtpk9aWZ/MrM3J9V3oPvP928m6p/d4W3C9R1h/ly8Gdjm7i8lpQ3p8Uo5NwzL3y8FmGHMzOqBnwOfd/dO4HvAccBpwBaCJvpQO9fdzwAuAC4zs7ckr/Tg3xsvQr0IH6P9fuBnYdJwOF6vMxTHaKD7MLMvETw99rYwaQsw091PB64Abjezxqj2n8aw/NklWcLR/8gM6fFKc27Iu6x85LoPBZiB20ww0JYwPUwrKDOrJPgFus3dfwHg7tvcvdfd+4AfAvOz1ClT+i5grJlVpKRn5e6bw/ftBIPC84FtZjYlrPcUgoHRfOq1OVxOTc/VBcAT7r4trGPRj1eSoThGmfbRLzP7OPBe4CPhiQN3j7n7rnD5cYLxjXl57n/AfzND9LM7vE24vinM368w798QDPgn6jtkxyvduSGPsobk90sBZuBWAnPNbHb4H/NiYFkhd2BmBtwEPO/u30hKn5KU7QPAc+HyMmCxmVWb2WxgLsFAXdq6hieRPwKLwu0vJujLzVavMWbWkFgmGO94Ltz/xWnKWgZ8zAJnAx1hE3s58G4zGxd2fbyboF98C9BpZmeHx+BjudQryVH/VRb7eKUYimOUaR8ZmdkC4IvA+939YFJ6i5mVh8vHEhyjdXnuP9N37K9eQ/GzS67vIuD+RIDN4p0E4xSHu5KG6nhlOjfkUdaQ/H4VdDC6VF4EMzNeJPgv5UsRlH8uQfPzGZKmaQK3EkwffCb8YU9J2uZLYX3WkjTzKlNdCWbbPEYwFfFnQHUO9TqWYHbO0wRTJL8UpjcD9xFMX/wDMD5MN+CGcN/PAm1JZX0i3Hc78L+S0tsITiYvA98hh2nK4XZjCP77bEpKK8rxIghyW4Aegj7sS4biGGXaR5Z6tRP0xSd+zxKzqj4Y/oyfAp4A3pfv/vv7jv3UK/KfHVATfm4P1x+brV5h+k+Af0jJOyTHi8znhqL/fqV76VYxIiISCXWRiYhIJBRgREQkEgowIiISCQUYERGJhAKMiIhEQgFGZIDMrNnMngpfW81sc9LnqizbtpnZtwa4v0+Y2bMW3DblOTNbGKZ/3MymDua7iERJ05RFBsHMvgLsd/evJ6VV+JF7Xw22/OnAnwjuoNsR3iKkxd3Xm9kDBDeEXFWIfYkUmlowIgVgZj8xs++b2Qrga2Y238weseDmh38xs+PDfG8zs7vD5a9YcCPHB8xsnZl9Nk3RE4F9wH4Ad98fBpdFBBfE3Ra2nGrN7EwLbrT4uJkttyO39XjAzP4rzPecmc1Psx+RglOAESmc6cCb3P0Kgod4vdmDmx9+Gfi/GbY5ATif4F5b/2bBfaaSPQ1sA9ab2Y/N7H0A7n4XsIrg/mGnEdyo8tvAInc/k+BhWdcklVMX5vtMuE4kchXZs4hIjn7m7r3hchNwi5nNJbi1R2rgSPiNu8eAmJltJ7gF+uF7XLl7b3i/sLOA84DrzexMd/9KSjnHAycD9wa3kKKc4DYnCT8Ny3vQzBrNbKy7783/q4pkpwAjUjgHkpb/D/BHd/+ABc/teCDDNrGk5V7S/E16MFD6GPCYmd0L/JjggVzJDFjt7udk2E/qYKsGXyVy6iITiUYTR25z/vF8CzGzqWZ2RlLSacAr4fI+gsfmQnDjxxYzOyfcrtLMTkra7kNh+rkEd9TtyLdOIrlSC0YkGl8j6CL7F+A3gyinEvh6OB25C9gB/EO47ifA983sEMGjgBcB3zKzJoK/7W8S3OEXoMvMngzL+8Qg6iOSM01TFhnlNJ1ZikVdZCIiEgm1YEREJBJqwYiISCQUYEREJBIKMCIiEgkFGBERiYQCjIiIROL/Bw+GxAaLg8ncAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "molecular-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(512)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "mexican-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba7d7b8f0ee4379a2ae5e3ae15b3e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0 >> loss: 5.4113, 5.3086, acc: 0.0114, 0.0118\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169169b43e8d4e28b5567ecb140d2b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 1 >> loss: 5.2193, 5.1629, acc: 0.0205, 0.0156\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00581c29be144029ab12045aba00d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-af3eb0920a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mstart_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-bfa1ddf18819>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataset, loss_fn, acc_fn, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mstart_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mend_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_GatherGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   2159\u001b[0m   \u001b[0mvalues_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m   \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m   \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8363\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8364\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 8365\u001b[0;31m         _ctx, \"Reshape\", name, tensor, shape)\n\u001b[0m\u001b[1;32m   8366\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8367\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(6):\n",
    "    train_epoch(model_mod, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model_mod, dev_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model_mod.save_weights(os.path.join(data_dir, \"korquad_bert_pretrain.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-rhythm",
   "metadata": {},
   "source": [
    "optimizer를 다시 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "deluxe-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=512)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "imported-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    0.0002, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fuzzy-messaging",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845a168b25534c0181df561fe2c39c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 2 >> loss: 5.1963, 5.1843, acc: 0.0223, 0.0172\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8413d3d87b5f46eca5f8f9c82a8d2856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 3 >> loss: 5.2067, 5.2244, acc: 0.0226, 0.0205\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ca7622df95479fa4720704aab40a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f6b488e2b6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mstart_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'eval {epoch+2} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-bfa1ddf18819>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataset, loss_fn, acc_fn, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mstart_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mend_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_GatherGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   2159\u001b[0m   \u001b[0mvalues_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m   \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m   \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8363\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8364\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 8365\u001b[0;31m         _ctx, \"Reshape\", name, tensor, shape)\n\u001b[0m\u001b[1;32m   8366\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8367\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(3):\n",
    "    train_epoch(model_mod, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model_mod, dev_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch+2} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model_mod.save_weights(os.path.join(data_dir, \"korquad_bert_pretrain_lr_const.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "lightweight-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, question, context):\n",
    "    \"\"\"\n",
    "    입력에 대한 답변 생성하는 함수\n",
    "    :param model: model\n",
    "    :param question: 입력 문자열\n",
    "    :param context: 입력 문자열\n",
    "    \"\"\"\n",
    "    q_tokens = vocab.encode_as_pieces(question)[:args.max_query_length]\n",
    "    c_tokens = vocab.encode_as_pieces(context)[:args.max_seq_length - len(q_tokens) - 3]\n",
    "    tokens = ['[CLS]'] + q_tokens + ['[SEP]'] + c_tokens + ['[SEP]']\n",
    "    token_ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "    token_ids += [0] * (args.max_seq_length - len(token_ids))\n",
    "    segments = [0] * (len(q_tokens) + 2) + [1] * (len(c_tokens) + 1)\n",
    "    segments += [0] * (args.max_seq_length - len(segments))\n",
    "\n",
    "    y_start, y_end = model((np.array([token_ids]), np.array([segments])))\n",
    "    # print(y_start, y_end)\n",
    "    y_start_idx = K.argmax(y_start, axis=-1)[0].numpy()\n",
    "    y_end_idx = K.argmax(y_end, axis=-1)[0].numpy()\n",
    "    answer_tokens = tokens[y_start_idx:y_end_idx + 1]\n",
    "\n",
    "    return vocab.decode_pieces(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "lucky-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "질문 :  임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?\n",
      "지문 :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "정답 :  여의도 농민 폭력 시위\n",
      "예측 :  여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌 \n",
      "\n",
      "9\n",
      "질문 :  국무회의의 심의를 거쳐야 한다는 헌법 제 몇 조의 내용인가?\n",
      "지문 :  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만도 못한 권한을 행사하고 있다.\"고 답변했다.\n",
      "정답 :  제89조\n",
      "예측 :  대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다 \n",
      "\n",
      "11\n",
      "질문 :  미국 군대 내 두번째로 높은 직위는 무엇인가?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  미국 육군 부참모 총장\n",
      "예측 :  높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 \n",
      "\n",
      "12\n",
      "질문 :  로널드 레이건 정부 출범 당시 알렉산더 헤이그는 어떤 직책을 맡았는가?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  초대 국무장관직\n",
      "예측 :  유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984 \n",
      "\n",
      "13\n",
      "질문 :  알렉산더 헤이그는 어느 대통령의 밑에서 국무장관을 지냈는가?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  로널드 레이건 대통령\n",
      "예측 :  Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 \n",
      "\n",
      "24\n",
      "질문 :  알렉산더 헤이그가 나온 대학교는?\n",
      "지문 :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "정답 :  노터데임 대학교\n",
      "예측 :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 \n",
      "\n",
      "27\n",
      "질문 :  헤이그가 군에서 퇴역한 해는 언제인가?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  1979년\n",
      "예측 :  유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 \n",
      "\n",
      "28\n",
      "질문 :  알렉산더 헤이그를 사성 장군과 육군 부참모로 진급시킨 대통령은 누구인가?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  닉슨 대통령\n",
      "예측 :  [SEP] 헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 \n",
      "\n",
      "30\n",
      "질문 :  헤이그가 군에서 퇴역한 년도는 몇년도입니까?\n",
      "지문 :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다. 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "정답 :  1979년\n",
      "예측 :  을 보내고 1979년 군에서 \n",
      "\n",
      "35\n",
      "질문 :  헤이그가 사적생활을 하다가 정계로 돌아갔던 해는 언제인가?\n",
      "지문 :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "정답 :  1988년\n",
      "예측 :  로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분 \n",
      "\n",
      "37\n",
      "질문 :  헤이그가 정계로 돌아간 년도는 몇년도입니까?\n",
      "지문 :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "정답 :  1988년\n",
      "예측 :  로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정 \n",
      "\n",
      "49\n",
      "질문 :  노아의 방주를 상징적 의미로 받아들이는 종교는 무엇인가?\n",
      "지문 :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "정답 :  기독교\n",
      "예측 :  에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아 \n",
      "\n",
      "52\n",
      "질문 :  전통 신학계의 근본주의적 시작을 여전히 받아들여 노아의 방주를 역사적 사실로 인식하는 집단은?\n",
      "지문 :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "정답 :  보수적 근본주의계열의 개신교\n",
      "예측 :  주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 \n",
      "\n",
      "60\n",
      "질문 :  현대에 노아의 방주에 대학 근본주의적 해석은 어떻게 여겨지는가?\n",
      "지문 :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, 과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, 홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "정답 :  비과학적인 해석\n",
      "예측 :  으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, \n",
      "\n",
      "63\n",
      "질문 :  노아의 방주가 역사적으로 실재했다는 주장은 무엇이 존재하지 않아 학계로부터 전혀 인정받지 못하고 있는가?\n",
      "지문 :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
      "정답 :  증거\n",
      "예측 :  주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 \n",
      "\n",
      "65\n",
      "질문 :  1955년 목재의 파편을 발견한 프랑스의 탐험가 이름은?\n",
      "지문 :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "정답 :  Fernand Navarra\n",
      "예측 :  1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 \n",
      "\n",
      "88\n",
      "질문 :  막부 해군이 정박하고 있던 시나가와 해역을 탈출한 시간은?\n",
      "지문 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "정답 :  자정\n",
      "예측 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 \n",
      "\n",
      "90\n",
      "질문 :  1868년 당시 일본의 해군 부총재는?\n",
      "지문 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "정답 :  에노모토 다케아키\n",
      "예측 :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_json = os.path.join(data_dir, \"korquad_dev.json\")\n",
    "\n",
    "with open(dev_json) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        question = vocab.decode_pieces(data['question'])\n",
    "        context = vocab.decode_pieces(data['context'])\n",
    "        answer = data['answer']\n",
    "        answer_predict = do_predict(model_mod, question, context)\n",
    "        if answer in answer_predict:\n",
    "            print(i)\n",
    "            print(\"질문 : \", question)\n",
    "            print(\"지문 : \", context)\n",
    "            print(\"정답 : \", answer)\n",
    "            print(\"예측 : \", answer_predict, \"\\n\")\n",
    "        if 100 < i:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-shield",
   "metadata": {},
   "source": [
    "정확도가 아주 높지는 못했다.(검증 0.0226) 4 EPOCH의 결과이므로, 더 훈련하면 좋은 결과를 낼 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-texture",
   "metadata": {},
   "source": [
    "# 회고\n",
    "1️⃣ 잘한 점:\n",
    "\n",
    "pretrained model의 일부를 freeze하고 뒤에 Dense Layer를 추가해 1024차원 Dense Layer와 384차원 Dense Layer만을 학습시키는 구조를 만들었다.\n",
    "\n",
    "적절한 optimizer와 learning rate scheduling을 통해 안정적 학습을 추구했다\n",
    "\n",
    "OOM 에러를 방지하기 위해 2 Epoch씩 훈련했다.\n",
    "\n",
    "예측에 정답이 거의 포함되었다.\n",
    "\n",
    "\n",
    "2️⃣ 어려웠던 점:\n",
    "\n",
    "모델 구조를 파악하는 것\n",
    "\n",
    "output dim을 384로 하는 Dense layer를 추가하는데 에러가 많이 나서, 수정하는데 많은 시간이 걸렸다\n",
    "\n",
    "3️⃣ 느낀 점:\n",
    "\n",
    "더욱 오래 훈련시킨다면 좋은 성과가 있을 것이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
