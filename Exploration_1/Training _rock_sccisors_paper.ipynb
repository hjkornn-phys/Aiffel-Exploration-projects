{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greatest-phase",
   "metadata": {},
   "source": [
    "## Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alternate-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916  images to be resized.\n",
      "916  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/Extracted_Processed/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "external-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910  images to be resized.\n",
      "910  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/Extracted_Processed/rock\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "foreign-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916  images to be resized.\n",
      "916  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/Extracted_Processed/paper\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-metallic",
   "metadata": {},
   "source": [
    "## Image Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suited-douglas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2742 입니다.\n",
      "x_train shape: (2742, 28, 28, 3)\n",
      "y_train shape: (2742,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=2742):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/Extracted_Processed\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fabulous-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  10\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 28, 28, 15)        195       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 28, 28, 15)        60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 14, 14, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 14, 14, 20)        1220      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 7, 7, 5)           405       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 3, 3, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 45)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 9)                 414       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 2,324\n",
      "Trainable params: 2,294\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(15, (2,2), activation='relu', input_shape=(28,28,3), padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(20, (2,2), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(5, (2,2), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(9, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "finite-pavilion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "86/86 [==============================] - 1s 4ms/step - loss: 1.0973 - accuracy: 0.4020\n",
      "Epoch 2/8\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8115 - accuracy: 0.6725\n",
      "Epoch 3/8\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7760\n",
      "Epoch 4/8\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8646\n",
      "Epoch 5/8\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8973\n",
      "Epoch 6/8\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9200\n",
      "Epoch 7/8\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9424\n",
      "Epoch 8/8\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41ecdca310>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-zoning",
   "metadata": {},
   "source": [
    "##  Load testset, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "spread-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109  images to be resized.\n",
      "109  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "109  images to be resized.\n",
      "109  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "109  images to be resized.\n",
      "109  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 327 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "import os\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "test_image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissors_paper/test\"\n",
    "(x_test, y_test)=load_data(test_image_path, number_of_data=327)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화, Training set 과 같은 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "several-montreal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7899 - accuracy: 0.6330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7898632287979126, 0.6330274939537048]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-complexity",
   "metadata": {},
   "source": [
    "**0.63의 정확도를 보였다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-panama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
